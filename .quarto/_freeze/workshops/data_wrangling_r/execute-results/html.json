{
  "hash": "cd1fe6fae8a08d160e45a8584e252e1c",
  "result": {
    "engine": "knitr",
    "markdown": "---\nexecute: \n  echo: true\n  message: false\n  warning: false\n  fig-format: \"svg\"\nformat: \n  revealjs:\n    highlight-style: a11y-dark\n    reference-location: margin\n    theme: csscr_styles.scss\n    slide-number: true\n    code-link: true\n    chalkboard: true\n    incremental: false \n    smaller: true\n    preview-links: true\n    code-line-numbers: true\n    history: false\n    progress: true\n    link-external-icon: true\n    code-annotations: hover\n    pointer:\n      color: \"#b18eb1\"\nrevealjs-plugins:\n  - pointer\n---\n\n::: {.cell}\n\n:::\n\n\n\n## {#title-slide data-menu-title=\"Data Wrangling in R\" background-image=\"images/rainier.png\" background-size=\"cover\" background-color=\"#4B2E83\"}\n\n[Data Wrangling in R]{.custom-title}\n\n[CSSCR Workshop]{.custom-subtitle}\n\n[31 October 2024]{.custom-subtitle2}\n\n[Victoria Sass]{.custom-subtitle3}\n\n## Roadmap\n\n::: {.incremental}\n* Importing and Exporting Data\n* Manipulating and Summarizing Data \n* Merging Data\n* Tidying and Reshaping Data\n:::\n\n# Importing and Exporting Data{.section-title background-color=\"#4B2E83\"}\n\n## Data Packages\n\nR has a *big* user base.  If you are working with a popular data source, it will often have a devoted R package on *CRAN* or *Github*. \n\n. . . \n\nExamples:\n\n* [`WDI`](https://vincentarelbundock.github.io/WDI/): World Development Indicators (World Bank)\n* [`tidycensus`](https://walker-data.com/tidycensus/): Census and American Community Survey\n* [`quantmod`](https://walker-data.com/tidycensus/): financial data from Yahoo, FRED, Google\n* [`gssr`](https://kjhealy.github.io/gssr/): The General Social Survey Cumulative Data (1972-2021)\n* [`psidR`](https://github.com/floswald/psidR): Panel Study of Income Dynamics (basic & public datasets)\n\n. . . \n\nIf you have an actual data file, you'll have to import it yourself...\n\n## Delimited Text Files\n\nBesides a package, it's easiest when data is stored in a text file. The most commonly encountered delimited file is a **.csv**.\n\n. . . \n\nA comma-separated values (.csv) file looks like the following: \n\n```\n\"Subject\",\"Depression\",\"Sex\",\"Week\",\"HamD\",\"Imipramine\"\n101,\"Non-endogenous\",\"Second\",0,26,NA\n101,\"Non-endogenous\",\"Second\",1,22,NA\n101,\"Non-endogenous\",\"Second\",2,18,4.04305\n101,\"Non-endogenous\",\"Second\",3,7,3.93183\n101,\"Non-endogenous\",\"Second\",4,4,4.33073\n101,\"Non-endogenous\",\"Second\",5,3,4.36945\n103,\"Non-endogenous\",\"First\",0,33,NA\n103,\"Non-endogenous\",\"First\",1,24,NA\n103,\"Non-endogenous\",\"First\",2,15,2.77259\n```\n\n# {data-menu-title=\"`readr``\" background-image=\"images/readr.png\" background-size=\"contain\" background-position=\"center\" .section-title background-color=\"#B7A57A\"}\n\n## `readr`\n\nR has some built-in functions for importing data, such as `read.table()` and `read.csv()`. \n\n. . . \n\nThe `readr` package provides similar functions, like `read_csv()`, that have slightly better features:\n\n::: {.incremental}\n* Faster!\n* Better defaults (e.g. doesn't automatically convert characters to factors)\n* A *bit* smarter about dates and times\n* Loading progress bars for large files\n:::\n\n. . . \n\n`readr` is one of the core `tidyverse` packages so loading `tidyverse` will load it too:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n. . . \n\nAlternatively, you can just load `readr` like so:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\n```\n:::\n\n\n\n## `readr` Importing Example\n\nLet's import some data about song ranks on the Billboard Hot 100 in 2000:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbillboard_2000_raw <- read_csv(file = \"data/billboard.csv\")\n```\n:::\n\n\n\n. . . \n\nHow do we know it loaded? \n\n. . . \n\nLet's look at it!\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nglimpse(billboard_2000_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 317\nColumns: 81\n$ year         <dbl> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 200…\n$ artist       <chr> \"2 Pac\", \"2Ge+her\", \"3 Doors Down\", \"3 Doors Down\", \"504 …\n$ track        <chr> \"Baby Don't Cry (Keep...\", \"The Hardest Part Of ...\", \"Kr…\n$ time         <time> 04:22:00, 03:15:00, 03:53:00, 04:24:00, 03:35:00, 03:24:…\n$ date.entered <date> 2000-02-26, 2000-09-02, 2000-04-08, 2000-10-21, 2000-04-…\n$ wk1          <dbl> 87, 91, 81, 76, 57, 51, 97, 84, 59, 76, 84, 57, 50, 71, 7…\n$ wk2          <dbl> 82, 87, 70, 76, 34, 39, 97, 62, 53, 76, 84, 47, 39, 51, 6…\n$ wk3          <dbl> 72, 92, 68, 72, 25, 34, 96, 51, 38, 74, 75, 45, 30, 28, 5…\n$ wk4          <dbl> 77, NA, 67, 69, 17, 26, 95, 41, 28, 69, 73, 29, 28, 18, 4…\n$ wk5          <dbl> 87, NA, 66, 67, 17, 26, 100, 38, 21, 68, 73, 23, 21, 13, …\n$ wk6          <dbl> 94, NA, 57, 65, 31, 19, NA, 35, 18, 67, 69, 18, 19, 13, 3…\n$ wk7          <dbl> 99, NA, 54, 55, 36, 2, NA, 35, 16, 61, 68, 11, 20, 11, 34…\n$ wk8          <dbl> NA, NA, 53, 59, 49, 2, NA, 38, 14, 58, 65, 9, 17, 1, 29, …\n$ wk9          <dbl> NA, NA, 51, 62, 53, 3, NA, 38, 12, 57, 73, 9, 17, 1, 27, …\n$ wk10         <dbl> NA, NA, 51, 61, 57, 6, NA, 36, 10, 59, 83, 11, 17, 2, 30,…\n$ wk11         <dbl> NA, NA, 51, 61, 64, 7, NA, 37, 9, 66, 92, 1, 17, 2, 36, N…\n$ wk12         <dbl> NA, NA, 51, 59, 70, 22, NA, 37, 8, 68, NA, 1, 3, 3, 37, N…\n$ wk13         <dbl> NA, NA, 47, 61, 75, 29, NA, 38, 6, 61, NA, 1, 3, 3, 39, N…\n$ wk14         <dbl> NA, NA, 44, 66, 76, 36, NA, 49, 1, 67, NA, 1, 7, 4, 49, N…\n$ wk15         <dbl> NA, NA, 38, 72, 78, 47, NA, 61, 2, 59, NA, 4, 10, 12, 57,…\n$ wk16         <dbl> NA, NA, 28, 76, 85, 67, NA, 63, 2, 63, NA, 8, 17, 11, 63,…\n$ wk17         <dbl> NA, NA, 22, 75, 92, 66, NA, 62, 2, 67, NA, 12, 25, 13, 65…\n$ wk18         <dbl> NA, NA, 18, 67, 96, 84, NA, 67, 2, 71, NA, 22, 29, 15, 68…\n$ wk19         <dbl> NA, NA, 18, 73, NA, 93, NA, 83, 3, 79, NA, 23, 29, 18, 79…\n$ wk20         <dbl> NA, NA, 14, 70, NA, 94, NA, 86, 4, 89, NA, 43, 40, 20, 86…\n$ wk21         <dbl> NA, NA, 12, NA, NA, NA, NA, NA, 5, NA, NA, 44, 43, 30, NA…\n$ wk22         <dbl> NA, NA, 7, NA, NA, NA, NA, NA, 5, NA, NA, NA, 50, 40, NA,…\n$ wk23         <dbl> NA, NA, 6, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, 39, NA,…\n$ wk24         <dbl> NA, NA, 6, NA, NA, NA, NA, NA, 9, NA, NA, NA, NA, 44, NA,…\n$ wk25         <dbl> NA, NA, 6, NA, NA, NA, NA, NA, 13, NA, NA, NA, NA, NA, NA…\n$ wk26         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, 14, NA, NA, NA, NA, NA, NA…\n$ wk27         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA, NA…\n$ wk28         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 23, NA, NA, NA, NA, NA, NA…\n$ wk29         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 22, NA, NA, NA, NA, NA, NA…\n$ wk30         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 33, NA, NA, NA, NA, NA, NA…\n$ wk31         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 36, NA, NA, NA, NA, NA, NA…\n$ wk32         <dbl> NA, NA, 3, NA, NA, NA, NA, NA, 43, NA, NA, NA, NA, NA, NA…\n$ wk33         <dbl> NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk34         <dbl> NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk35         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk36         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk37         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk38         <dbl> NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk39         <dbl> NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk40         <dbl> NA, NA, 15, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk41         <dbl> NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk42         <dbl> NA, NA, 13, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk43         <dbl> NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk44         <dbl> NA, NA, 16, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk45         <dbl> NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk46         <dbl> NA, NA, 21, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk47         <dbl> NA, NA, 22, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk48         <dbl> NA, NA, 24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk49         <dbl> NA, NA, 28, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk50         <dbl> NA, NA, 33, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk51         <dbl> NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk52         <dbl> NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk53         <dbl> NA, NA, 49, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk54         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk55         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk56         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk57         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk58         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk59         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk60         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk61         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk62         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk63         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk64         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk65         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk66         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk67         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk68         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk69         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk70         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk71         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk72         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk73         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk74         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk75         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk76         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n```\n\n\n:::\n:::\n\n\n\n## Alternate Solution\n\nWhen you import data from an external file you'll also see it in the Global Environment tab in the upper-right pane of RStudio: \n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n::: {.fragment}\nYou can also import the data manually!\n\nIn the upper right-hand pane of RStudio (make sure you're in the Environment tab), select:\n\n`Import Dataset > From Text (readr)` and browse to the file on your computer^[Ideally you've saved it in your project folder!].\n:::\n\n::: {.fragment}\n**Once you've imported the data, you can `copy/paste` the import code from the console into your file!!**\n\nThis makes the process *reproducible!*\n:::\n:::\n::: {.column width=\"50%\"}\n![](images/data_global_env.png)\n\n:::\n\n::::\n\n## Manual Data Import\n\n![](images/data_import_manual.png){fig-align=\"center\"}\n\n## Specifying `NA`s \n\nSometimes a particular dataset or file read from a different software will code `NA`s differently than `R`. If that's the case, you can add additional specifications to `read_csv` for what to read in as `NA`.  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2\"}\nbillboard_2000_raw <- read_csv(file = \"data/billboard.csv\", \n                               na = c(\"N/A\", \"999\"))\n```\n:::\n\n\n\n## Skipping lines\n\nDepending on how the data were input, there may be several lines that precede the beginning of the data table you're interested in importing. You can skip these lines of metadata with the `skip` argument:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2\"}\nbillboard_2000_raw <- read_csv(file = \"data/billboard.csv\", \n                               skip = 1)\n```\n:::\n\n\n\n## Variable names\n\n`read_csv` will automatically take the first row as column names. If you want to rename them you can save yourself some time recoding later on if you specify your preferred variable names upfront with the `col_names` argument. \n\n. . . \n\nIt takes a character vector to be used as column names (in their order of appearance). \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbillboard_renamed <- read_csv(file = \"data/billboard.csv\",\n                              col_names = c(\"year\", \"artist\", \"track\", \"time\", \"date_entered\", \n                                            paste(\"wk\", 1:76, sep = \"_\"))) # <1>\n\nbillboard_renamed |>  names() |> head(10) # <2>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"year\"         \"artist\"       \"track\"        \"time\"         \"date_entered\"\n [6] \"wk_1\"         \"wk_2\"         \"wk_3\"         \"wk_4\"         \"wk_5\"        \n```\n\n\n:::\n:::\n\n\n1. First few entries: \"wk_1\"  \"wk_2\"  \"wk_3\"\n2. `names` returns the column names.\n\n. . . \n\nIf you don't have any variable names you can specify that instead. \n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2\"}\nbillboard_2000_raw <- read_csv(file = \"data/billboard.csv\", \n                               col_names = FALSE) \n```\n:::\n\n\n\n## Snake Case\n\nIf you simply want to change your variables to snake case (all lower case; words separated by `_`), you can use the function `clean_names()` from the `janitor` package which replaces other punctuation separators with `_`. \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Download package first\n# install.packages(\"janitor\") # <3> \n\n# Create new object for renamed data\nbillboard_renamed <- billboard_2000_raw |> \n  janitor::clean_names(numerals = \"right\") # <4>\n\nbillboard_renamed |>  names() |> head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"year\"         \"artist\"       \"track\"        \"time\"         \"date_entered\"\n [6] \"wk_1\"         \"wk_2\"         \"wk_3\"         \"wk_4\"         \"wk_5\"        \n```\n\n\n:::\n:::\n\n\n\n3. Run in the console first. \n4. You can call a function without loading its package by specifying its package name followed by `::` before it; <br> The `numerals` argument specifies if you additionally want to put a separator before a number. \n\n## Other Data File Types with `readr`\n\nThe other functions in `readr` employ a similar approach to `read_csv` so the trick is just knowing which to use for what data type. \n\n. . . \n\n* `read_csv2` is separated by semicolons (instead of commas)\n* `read_tsv` is separated by tabs\n* `read_delim` guesses the delimiter\n* `read_fwf` reads in fixed-width-files\n* `read_table` is a variation of `fwf` where columns are separated by white space\n* `read_log` reads in Apache-style log files\n\n\n## Other Packages to Read in Data\n\nThere are a range of other ways, besides delimited files, that data are stored. \n\nThe following packages are part of the extended `tidyverse` and therefore operate with similar syntax and logic as `readr`.\n\n## Other Packages to Read in Data\n\nThere are a range of other ways, besides delimited files, that data are stored. \n\nThe following packages are part of the extended `tidyverse` and therefore operate with similar syntax and logic as `readr`.\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](images/readxl.png){.absolute top=185 left=135}\n:::\n::: {.column width=\"50%\"}\n* For Excel files (`.xls` or `.xlsx`), use package [`readxl`](https://readxl.tidyverse.org/)^[Functions have additional arguments to read in specific sheets or a range of cells.]\n:::\n::::\n\n::: aside\nNote: For Excel files and Googlesheets You **won't** keep text formatting, color, comments, or merged cells. See the [`openxlsx`](https://ycphs.github.io/openxlsx/) package for those capabilities. Also, [`tidyxl`](https://github.com/nacnudus/tidyxl) can help import non-tabular data from Excel. \n:::\n\n## Other Packages to Read in Data\n\nThere are a range of other ways, besides delimited files, that data are stored. \n\nThe following packages are part of the extended `tidyverse` and therefore operate with similar syntax and logic as `readr`.\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](images/googlesheets4.png){.absolute top=185 left=135}\n:::\n::: {.column width=\"50%\"}\n* For Excel files (`.xls` or `.xlsx`), use package [`readxl`](https://readxl.tidyverse.org/)^[Functions have additional arguments to read in specific sheets or a range of cells.]\n* For Google Docs Spreadsheets, use package [`googlesheets4`](https://googlesheets4.tidyverse.org/)^[Very similar to `readxl` with some slight variations you can read about [here](https://r4ds.hadley.nz/spreadsheets.html#google-sheets).]\n:::\n::::\n\n::: aside\nNote: For Excel files and Googlesheets You **won't** keep text formatting, color, comments, or merged cells. See the [`openxlsx`](https://ycphs.github.io/openxlsx/) package for those capabilities. Also, [`tidyxl`](https://github.com/nacnudus/tidyxl) can help import non-tabular data from Excel. \n:::\n\n## Other Packages to Read in Data\n\nThere are a range of other ways, besides delimited files, that data are stored. \n\nThe following packages are part of the extended `tidyverse` and therefore operate with similar syntax and logic as `readr`.\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](images/haven.png){.absolute top=185 left=135}\n:::\n::: {.column width=\"50%\"}\n* For Excel files (`.xls` or `.xlsx`), use package [`readxl`](https://readxl.tidyverse.org/)^[Functions have additional arguments to read in specific sheets or a range of cells.]\n* For Google Docs Spreadsheets, use package [`googlesheets4`](https://googlesheets4.tidyverse.org/)^[Very similar to `readxl` with some slight variations you can read about [here](https://r4ds.hadley.nz/spreadsheets.html#google-sheets).]\n* For Stata, SPSS, and SAS files, use package [`haven`](https://haven.tidyverse.org/)^[SAS, SPSS, and Stata have so-called \"labelled\" vectors for which `haven` provides a [class](https://haven.tidyverse.org/reference/index.html#labelled-vectors) to represent in `R`. Alternatively, you can get rid of them with [these functions](https://haven.tidyverse.org/reference/index.html#remove-attributes).]\n:::\n::::\n\n::: aside\nNote: For Excel files and Googlesheets You **won't** keep text formatting, color, comments, or merged cells. See the [`openxlsx`](https://ycphs.github.io/openxlsx/) package for those capabilities. Also, [`tidyxl`](https://github.com/nacnudus/tidyxl) can help import non-tabular data from Excel. \n:::\n\n## How does `readr` parse different data types?\n\nFor each column in a data frame, `readr` functions pull the first 1000 rows and checks:\n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-width: 11\n%%| fig-height: 5.5\n%%| fig-align: center\nflowchart LR\n    id1((Variable))==>A([\"1. Does it contain only F, T, FALSE, TRUE, or NA (ignoring case)?\"])==>id2{{Logical}}\n    id1((Variable))==>B([\"2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)\"])==>id3{{Number}}\n    id1((Variable))==>C([\"3. Does it match the ISO8601 standard?\"])==>id4{{Date/Date-time}}\n    id1((Variable))==>D([\"4. None of the above\"])==>id5{{String}}\n    style id1 fill:#4B2E83,color:#B7A57A,stroke:#B7A57A\n    style id2 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id3 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id4 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id5 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style A fill:#FFFFFF,color:#000000,stroke:#000000\n    style B fill:#FFFFFF,color:#000000,stroke:#000000\n    style C fill:#FFFFFF,color:#000000,stroke:#000000\n    style D fill:#FFFFFF,color:#000000,stroke:#000000\n\n```\n\n\n\n## How does `readr` parse different data types?\n\nFor each column in a data frame, `readr` functions pull the first 1000 rows and checks: \n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-width: 11\n%%| fig-height: 5.5\n%%| fig-align: center\nflowchart LR\n    id1((Variable))==>A([\"1. Does it contain only F, T, FALSE, TRUE, or NA (ignoring case)?\"])==>id2{{Logical}}\n    id1((Variable))==>B([\"2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)\"])==>id3{{Number}}\n    id1((Variable))==>C([\"3. Does it match the ISO8601 standard?\"])==>id4{{Date/Date-time}}\n    id1((Variable))==>D([\"4. None of the above\"])==>id5{{String}}\n    style id1 fill:#4B2E83,color:#B7A57A,stroke:#B7A57A\n    style id2 fill:#4B2E83,color:#B7A57A,stroke:#B7A57A\n    style id3 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id4 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id5 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style A fill:#B7A57A,color:#000000,stroke:#000000\n    style B fill:#FFFFFF,color:#000000,stroke:#000000\n    style C fill:#FFFFFF,color:#000000,stroke:#000000\n    style D fill:#FFFFFF,color:#000000,stroke:#000000\n\n```\n\n\n\n## How does `readr` parse different data types?\n\nFor each column in a data frame, `readr` functions pull the first 1000 rows and checks:\n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-width: 11\n%%| fig-height: 5.5\n%%| fig-align: center\nflowchart LR\n    id1((Variable))==>A([\"1. Does it contain only F, T, FALSE, TRUE, or NA (ignoring case)?\"])==>id2{{Logical}}\n    id1((Variable))==>B([\"2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)\"])==>id3{{Number}}\n    id1((Variable))==>C([\"3. Does it match the ISO8601 standard?\"])==>id4{{Date/Date-time}}\n    id1((Variable))==>D([\"4. None of the above\"])==>id5{{String}}\n    style id1 fill:#4B2E83,color:#B7A57A,stroke:#B7A57A\n    style id2 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id3 fill:#4B2E83,color:#B7A57A,stroke:#B7A57A\n    style id4 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id5 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style A fill:#FFFFFF,color:#000000,stroke:#000000\n    style B fill:#B7A57A,color:#000000,stroke:#000000\n    style C fill:#FFFFFF,color:#000000,stroke:#000000\n    style D fill:#FFFFFF,color:#000000,stroke:#000000\n\n```\n\n\n\n## How does `readr` parse different data types?\n\nFor each column in a data frame, `readr` functions pull the first 1000 rows and checks:\n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-width: 11\n%%| fig-height: 5.5\n%%| fig-align: center\nflowchart LR\n    id1((Variable))==>A([\"1. Does it contain only F, T, FALSE, TRUE, or NA (ignoring case)?\"])==>id2{{Logical}}\n    id1((Variable))==>B([\"2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)\"])==>id3{{Number}}\n    id1((Variable))==>C([\"3. Does it match the ISO8601 standard?\"])==>id4{{Date/Date-time}}\n    id1((Variable))==>D([\"4. None of the above\"])==>id5{{String}}\n    style id1 fill:#4B2E83,color:#B7A57A,stroke:#B7A57A\n    style id2 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id3 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id4 fill:#4B2E83,color:#B7A57A,stroke:#B7A57A\n    style id5 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style A fill:#FFFFFF,color:#000000,stroke:#000000\n    style B fill:#FFFFFF,color:#000000,stroke:#000000\n    style C fill:#B7A57A,color:#000000,stroke:#000000\n    style D fill:#FFFFFF,color:#000000,stroke:#000000\n\n```\n\n\n\n## How does `readr` parse different data types?\n\nFor each column in a data frame, `readr` functions pull the first 1000 rows and checks:\n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-width: 11\n%%| fig-height: 5.5\n%%| fig-align: center\nflowchart LR\n    id1((Variable))==>A([\"1. Does it contain only F, T, FALSE, TRUE, or NA (ignoring case)?\"])==>id2{{Logical}}\n    id1((Variable))==>B([\"2. Does it contain only numbers (e.g., 1, -4.5, 5e6, Inf?)\"])==>id3{{Number}}\n    id1((Variable))==>C([\"3. Does it match the ISO8601 standard?\"])==>id4{{Date/Date-time}}\n    id1((Variable))==>D([\"4. None of the above\"])==>id5{{String}}\n    style id1 fill:#4B2E83,color:#B7A57A,stroke:#B7A57A\n    style id2 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id3 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id4 fill:#B7A57A,color:#4B2E83,stroke:#4B2E83\n    style id5 fill:#4B2E83,color:#B7A57A,stroke:#B7A57A\n    style A fill:#FFFFFF,color:#000000,stroke:#000000\n    style B fill:#FFFFFF,color:#000000,stroke:#000000\n    style C fill:#FFFFFF,color:#000000,stroke:#000000\n    style D fill:#B7A57A,color:#000000,stroke:#000000\n\n```\n\n\n\n## Most Common Issue with Reading in Data\n\nThe most common problem that occurs when reading in data is having mixed data. Most often, given the heuristic provided in the last slide, `R` will parse a variable as a character string to preserve whatever it contains. \n\n. . . \n\nLet's actually look at how the billboard data was read in: \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nglimpse(billboard_2000_raw) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 317\nColumns: 81\n$ year         <dbl> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 200…\n$ artist       <chr> \"2 Pac\", \"2Ge+her\", \"3 Doors Down\", \"3 Doors Down\", \"504 …\n$ track        <chr> \"Baby Don't Cry (Keep...\", \"The Hardest Part Of ...\", \"Kr…\n$ time         <time> 04:22:00, 03:15:00, 03:53:00, 04:24:00, 03:35:00, 03:24:…\n$ date.entered <date> 2000-02-26, 2000-09-02, 2000-04-08, 2000-10-21, 2000-04-…\n$ wk1          <dbl> 87, 91, 81, 76, 57, 51, 97, 84, 59, 76, 84, 57, 50, 71, 7…\n$ wk2          <dbl> 82, 87, 70, 76, 34, 39, 97, 62, 53, 76, 84, 47, 39, 51, 6…\n$ wk3          <dbl> 72, 92, 68, 72, 25, 34, 96, 51, 38, 74, 75, 45, 30, 28, 5…\n$ wk4          <dbl> 77, NA, 67, 69, 17, 26, 95, 41, 28, 69, 73, 29, 28, 18, 4…\n$ wk5          <dbl> 87, NA, 66, 67, 17, 26, 100, 38, 21, 68, 73, 23, 21, 13, …\n$ wk6          <dbl> 94, NA, 57, 65, 31, 19, NA, 35, 18, 67, 69, 18, 19, 13, 3…\n$ wk7          <dbl> 99, NA, 54, 55, 36, 2, NA, 35, 16, 61, 68, 11, 20, 11, 34…\n$ wk8          <dbl> NA, NA, 53, 59, 49, 2, NA, 38, 14, 58, 65, 9, 17, 1, 29, …\n$ wk9          <dbl> NA, NA, 51, 62, 53, 3, NA, 38, 12, 57, 73, 9, 17, 1, 27, …\n$ wk10         <dbl> NA, NA, 51, 61, 57, 6, NA, 36, 10, 59, 83, 11, 17, 2, 30,…\n$ wk11         <dbl> NA, NA, 51, 61, 64, 7, NA, 37, 9, 66, 92, 1, 17, 2, 36, N…\n$ wk12         <dbl> NA, NA, 51, 59, 70, 22, NA, 37, 8, 68, NA, 1, 3, 3, 37, N…\n$ wk13         <dbl> NA, NA, 47, 61, 75, 29, NA, 38, 6, 61, NA, 1, 3, 3, 39, N…\n$ wk14         <dbl> NA, NA, 44, 66, 76, 36, NA, 49, 1, 67, NA, 1, 7, 4, 49, N…\n$ wk15         <dbl> NA, NA, 38, 72, 78, 47, NA, 61, 2, 59, NA, 4, 10, 12, 57,…\n$ wk16         <dbl> NA, NA, 28, 76, 85, 67, NA, 63, 2, 63, NA, 8, 17, 11, 63,…\n$ wk17         <dbl> NA, NA, 22, 75, 92, 66, NA, 62, 2, 67, NA, 12, 25, 13, 65…\n$ wk18         <dbl> NA, NA, 18, 67, 96, 84, NA, 67, 2, 71, NA, 22, 29, 15, 68…\n$ wk19         <dbl> NA, NA, 18, 73, NA, 93, NA, 83, 3, 79, NA, 23, 29, 18, 79…\n$ wk20         <dbl> NA, NA, 14, 70, NA, 94, NA, 86, 4, 89, NA, 43, 40, 20, 86…\n$ wk21         <dbl> NA, NA, 12, NA, NA, NA, NA, NA, 5, NA, NA, 44, 43, 30, NA…\n$ wk22         <dbl> NA, NA, 7, NA, NA, NA, NA, NA, 5, NA, NA, NA, 50, 40, NA,…\n$ wk23         <dbl> NA, NA, 6, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, 39, NA,…\n$ wk24         <dbl> NA, NA, 6, NA, NA, NA, NA, NA, 9, NA, NA, NA, NA, 44, NA,…\n$ wk25         <dbl> NA, NA, 6, NA, NA, NA, NA, NA, 13, NA, NA, NA, NA, NA, NA…\n$ wk26         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, 14, NA, NA, NA, NA, NA, NA…\n$ wk27         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA, NA…\n$ wk28         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 23, NA, NA, NA, NA, NA, NA…\n$ wk29         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 22, NA, NA, NA, NA, NA, NA…\n$ wk30         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 33, NA, NA, NA, NA, NA, NA…\n$ wk31         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 36, NA, NA, NA, NA, NA, NA…\n$ wk32         <dbl> NA, NA, 3, NA, NA, NA, NA, NA, 43, NA, NA, NA, NA, NA, NA…\n$ wk33         <dbl> NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk34         <dbl> NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk35         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk36         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk37         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk38         <dbl> NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk39         <dbl> NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk40         <dbl> NA, NA, 15, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk41         <dbl> NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk42         <dbl> NA, NA, 13, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk43         <dbl> NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk44         <dbl> NA, NA, 16, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk45         <dbl> NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk46         <dbl> NA, NA, 21, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk47         <dbl> NA, NA, 22, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk48         <dbl> NA, NA, 24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk49         <dbl> NA, NA, 28, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk50         <dbl> NA, NA, 33, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk51         <dbl> NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk52         <dbl> NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk53         <dbl> NA, NA, 49, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk54         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk55         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk56         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk57         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk58         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk59         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk60         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk61         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk62         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk63         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk64         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk65         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk66         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk67         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk68         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk69         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk70         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk71         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk72         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk73         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk74         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk75         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk76         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n```\n\n\n:::\n:::\n\n\n\n## What Went Wrong? \n\nSince `readr` uses the values in the first 1000 rows to guess the type of the column (logical, numeric, date/date-time, character), if the first 1000 rows don't have any data, they will be coded as logical variables. \n\n. . . \n\nThere are not many songs in the data that charted for 60+ weeks—and none in the first 1000 that charted for 66+ weeks!\n\n. . . \n\n::: {.callout-note icon=false}\n\n## <span style=\"color:blue\">{{< fa circle-info >}}</span> \\ `NA` is logical?\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nclass(c(T, F, NA, FALSE, TRUE))\nclass(c(1, NA, 17.5, 5.3, NA)) # <5>\nclass(as.Date(c(NA, \"2023-10-31\", \"1986-06-21\", \"1997-01-15\"), tz = \"America/Los_Angeles\")) # <6>\nclass(c(\"apple\", NA, \"mango\", \"blackberry\", \"plum\")) \nclass(c(NA, NA, NA, NA, NA))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"logical\"\n[1] \"numeric\"\n[1] \"Date\"\n[1] \"character\"\n[1] \"logical\"\n```\n\n\n:::\n:::\n\n\n\n5. `class` returns the data type of its first argument. \n6. `as.Date` turns a character string of dates into an official date class in Base `R`. If we had an accompanying time stamp we would need to use `as.POSIXct` which turns a character string of dates and times into an official date-time class in Base `R`. \n:::\n\n::: aside\nTechnically, `NA`s can be any data type depending upon what they are grouped with. However, by themselves they are a logical indicator of missing data, so their class is logical. \n:::\n\n## Column types\n\nSince the `wk*` variables should all be read in as integers, we can specify this explicitly with the `col_types` argument. \n\n. . . \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\n# Create character string of shortcode column types\nbb_types <- paste(c(\"icctD\", rep(\"i\", 76)), collapse=\"\") # <7>\nbb_types \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"icctDiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\"\n```\n\n\n:::\n:::\n\n\n\n7. You can short-code column types with `i` = integer, `c` = character, `t` = time, `D` = date. <br> The `collapse` argument collapses the first two arguments into one complete character string.\n\n. . . \n\n<br>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# re-read in data with column types specified\nbillboard_2000_raw <- read_csv(file = \"data/billboard.csv\", \n                               col_types = bb_types) # <8>\n```\n:::\n\n\n8. See all column types and short codes [here](https://readr.tidyverse.org/reference/cols.html).\n\n## Column types\n\nTo specify a default column type you can use `.default` like so: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbillboard_2000_raw <- read_csv(file = \"data/billboard.csv\", \n                               col_types = cols(.default = col_character())) \n```\n:::\n\n\n\n. . . \n\n<br>\n\nAnother useful helper is `cols_only()` for when you only want to read in a subset of all available variables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbillboard_2000_raw <- read_csv(file = \"data/billboard.csv\", \n                               col_types = cols_only(x = col_character)) \n```\n:::\n\n\n\n. . . \n\n<br>\n\nIn summary, the `col_types` argument gives you greater control over how your data are read in and can save you recoding time down the road and/or point out where your data are behaving differently than you expect. \n\n## Writing Delimited Files\n\nGetting data out of R into a delimited file is very similar to getting it into R:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(billboard_2000_raw, path = \"data/billboard_data.csv\")\n```\n:::\n\n\n\nThis saved the data we pulled off the web in a file called `billboard_data.csv` in the `data` folder of my working directory.\n\n. . . \n\nHowever, saving data in this way will not preserve `R` data types since delimited files code everything as a character string. \n\n. . . \n\nTo save `R` objects and all associated metadata you have two options: \n\n::: {.panel-tabset}\n\n### `.Rds` format:\n\n* Used for single objects, doesn't save the original object name\n* Save: `write_rds(old_object_name, \"path.Rds\")`\n* Load: `new_object_name <- read_rds(\"path.Rds\")`\n\n### `.Rdata` or `.Rda` format:\n\n* Used for saving multiple files where the original object names are preserved\n* Save: `save(object1, object2, ... , file = \"path.Rdata\")`\n* Load: `load(\"path.Rdata\")` without assignment operator\n\n:::\n\n## Writing Other File-Types\n\n::: {.panel-tabset}\n\n### `writexl`\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n* `write_xlsx()` writes to an xlsx file\n:::\n\n::: {.column width=\"40%\"}\n![](images/writexl.png){width=50%}\n:::\n\n::::\n\n### `googlesheets4`\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n* `sheet_write()` or `write_sheet()` (over)writes new data into a Sheet\n* `gs4_create()` creates a new Sheet\n* `sheet_append()` appends rows to a sheet\n* `range_write()` (over)writes new data into a range\n* `range_flood()` floods a range of cells\n* ``range_clear()` clears a range of cells\n:::\n\n::: {.column width=\"40%\"}\n![](images/googlesheets4.png){width=50%}\n:::\n\n::::\n\n### `haven`\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n* `write_dta()` writes Stata DTA files\n* `write_sav()` writes SPSS files\n* `write_xpt()` writes SAS transport files\n:::\n\n::: {.column width=\"40%\"}\n![](images/haven.png){width=50%}\n:::\n\n::::\n\n:::\n\n# Manipulating and Summarizing Data{.section-title background-color=\"#4B2E83\"}\n\n## Death to Spreadsheets\n\nTools like *Excel* or *Google Sheets* let you manipulate spreadsheets using functions.\n\n::: {.incremental}\n* Spreadsheets are *not reproducible*: It's hard to know how someone changed the raw data!\n* It's hard to catch mistakes when you use spreadsheets^[Don't be the next sad Research Assistant who makes headlines with an Excel error! ([Reinhart & Rogoff, 2010](http://www.bloomberg.com/news/articles/2013-04-18/faq-reinhart-rogoff-and-the-excel-error-that-changed-history))].\n:::\n \n. . .  \n \nWe want to know how to use `R` to manipulate data more *transparently* and *reproducibly*.\n\n# Logical Operators{.section-title background-color=\"#B7A57A\"}\n\n## Data types in `R`\n\nThere are a variety of data types in `R`: \n\n. . . \n\n* Factors\n* Date/Date-time\n* Logical\n* Numeric\n* Missing Values\n* Strings\n\n## Data types in `R`\n\nThere are a variety of data types in `R`: \n\n* Factors\n* Date/Date-time\n* <span style=\"color:#e15759\">Logical</span>\n* Numeric\n* Missing Values\n* Strings\n\n## Logical Operators in `R`\n  \n#### Comparing objects\n:::: {.columns}\n\n::: {.column width=\"19%\"}\n::: {.fragment}\n* `==`: \n* `!=`: \n* `>`, `>=`, `<`, `<=`: \n* `%in%`: \n:::\n:::\n\n::: {.column width=\"81%\"}\n\n::: {.fragment}\n* is equal to^[Note: there are TWO equal signs here!]\n* not equal to\n* less than, less than or equal to, etc.\n* used when checking if equal to one of several values\n:::\n:::\n\n::::\n\n:::{.fragment}\n#### Combining comparisons\n:::\n\n:::: {.columns}\n\n::: {.column width=\"19%\"}\n::: {.fragment}\n* `&`: \n* `|`: \n* `!`: \n* `xor()`:\n:::\n:::\n\n::: {.column width=\"81%\"}\n\n::: {.fragment .bullet-spacing}\n* **both** conditions need to hold (AND)\\\n* **at least one** condition needs to hold (OR)\\\n* **inverts** a logical condition (`TRUE` becomes `FALSE`, vice versa)\\\n* **exclusive OR** (i.e. x or y but NOT both)\n:::\n:::\n\n::::\n\n::: aside\nYou may also see `&&` and `||` but they are what's known as short-circuiting operators and are not to be used in `dplyr` functions (used for programming not data manipulation); they'll only ever return a single `TRUE` or `FALSE`.\n:::\n\n## Logical Summaries\n\n:::: {.columns}\n\n::: {.column width=\"19%\"}\n::: {.fragment}\n* `any()`: \n* `all()`: \n:::\n:::\n\n::: {.column width=\"81%\"}\n\n::: {.fragment}\n* the equivalent of `|`; it’ll return `TRUE` if there are any `TRUE`’s in x\n* the equivalent of `&`; it’ll return `TRUE` only if all values of x are `TRUE`’s\n:::\n:::\n\n::::\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nC <- c(5, 10, NA, 10, 20, NA)\nany(C <= 10) \nall(C <= 20) # <1> \nall(C <= 20, na.rm = TRUE) # <2>\nmean(C, na.rm = TRUE) # <3> \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n[1] NA\n[1] TRUE\n[1] 11.25\n```\n\n\n:::\n:::\n\n\n1. Like other summary functions, they'll return `NA` if there are any missing values present and it's `FALSE`. \n2. Use `na.rm = TRUE` to remove `NA`s prior to evaluation. \n3. When you evaluate a logical vector numerically, `TRUE` = 1 and `FALSE` = 0. This makes `sum()` and `mean()` useful when summarizing logical functions (sum gives number of `TRUE`s and mean gives the proportion). \n\n## Conditional transformations\n\n<ins>**`if_else()`**</ins>\n\nIf you want to use one value when a condition is `TRUE` and another value when it’s `FALSE`.\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif_else(condition = \"A logical vector\", \n        true = \"Output when condition is true\", \n        false = \"Output when condition is false\")\n```\n:::\n\n\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(-3:3, NA)\nif_else(x > 0, \"+ve\", \"-ve\", \"???\") # <4> \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"-ve\" \"-ve\" \"-ve\" \"-ve\" \"+ve\" \"+ve\" \"+ve\" \"???\"\n```\n\n\n:::\n:::\n\n\n4. There’s an optional fourth argument, `missing` which will be used if the input is `NA`.\n\n. . . \n\n<ins>**`case_when()`**</ins>\n\nA very useful extension of `if_else()` for multiple conditions^[Note that if multiple conditions match in `case_when()`, only the first will be used. \n]. \n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncase_when(\n  x == 0   ~ \"0\",\n  x < 0    ~ \"-ve\", \n  x > 0    ~ \"+ve\",\n  is.na(x) ~ \"???\" # <5>\n) # <6> \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"-ve\" \"-ve\" \"-ve\" \"0\"   \"+ve\" \"+ve\" \"+ve\" \"???\"\n```\n\n\n:::\n:::\n\n\n\n5. Use `.default` if you want to create a “default”/catch all value. \n6. Both functions require compatible types: i.e. numerical and logical, strings and factors, dates and datetimes, `NA` and everything. \n\n# {data-menu-title=\"`dplyr`\" background-image=\"images/dplyr.png\" background-size=\"contain\" background-position=\"center\" .section-title background-color=\"#B7A57A\"}\n\n## `dplyr`\n\nToday, we'll use tools from the `dplyr` package to manipulate data! \n\n* `dplyr` is part of the *Tidyverse*, and included in the `tidyverse` package. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n. . . \n\nTo demonstrate data transformations we're going to use the `nycflights13` dataset, which you'll need to download and load into `R`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Download and load data\n# install.packages(\"nycflights13\") # <7>\nlibrary(nycflights13) # <8>\n```\n:::\n\n\n\n7. Run in console. \n8. Load into `R` session. \n\n. . . \n\n`nycflights13` includes five dataframes^[Note these are separate data frames, each needing to be loaded separately:], some of which contain missing data (`NA`):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(flights) # <9> \ndata(airlines) # <10>\ndata(airports) # <11>\ndata(planes) # <12>\ndata(weather) # <13>\n```\n:::\n\n\n\n9. flights leaving JFK, LGA, or EWR in 2013\n10. airline abbreviations\n11. airport metadata\n12. airplane metadata\n13. hourly weather data for JFK, LGA, and EWR\n\n## `dplyr` Basics\n\nAll `dplyr` functions have the following in common: \n\n::: {.incremental}\n1. The first argument is always a data frame.\n2. The subsequent arguments typically describe which columns to operate on, using the variable names (without quotes).\n3. The output is always a new data frame.\n:::\n\n. . . \n\nEach function operates either on rows, columns, groups, or entire tables.\n\n. . . \n\nTo save the transformations you've made to a data frame you'll need to save the output to a new object. \n\n# Subsetting data{.section-title background-color=\"#B7A57A\"}\n\n## Subset Rows: `filter()`\n\nWe often get *big* datasets, and we only want some of the entries. We can subset rows using `filter()`.\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndelay_2hr <- flights |> \n  filter(dep_delay > 120) # <14>\ndelay_2hr # <15>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9,723 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      848           1835       853     1001           1950\n 2  2013     1     1      957            733       144     1056            853\n 3  2013     1     1     1114            900       134     1447           1222\n 4  2013     1     1     1540           1338       122     2020           1825\n 5  2013     1     1     1815           1325       290     2120           1542\n 6  2013     1     1     1842           1422       260     1958           1535\n 7  2013     1     1     1856           1645       131     2212           2005\n 8  2013     1     1     1934           1725       129     2126           1855\n 9  2013     1     1     1938           1703       155     2109           1823\n10  2013     1     1     1942           1705       157     2124           1830\n# ℹ 9,713 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n14. Here's where we'll use a lot of logical operators. Make sure to use `==` not `=` to test the logical condition. \n15. Now, `delay_2hr` is an object in our environment which contains rows corresponding to flights that experienced at least a 2 hour delay.\n\n## Subset Columns: `select()`\n\nWhat if we want to keep every observation, but only use certain variables? Use `select()`!\n\n. . . \n\nWe can select columns by name: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  select(year, month, day) # <16>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 3\n    year month   day\n   <int> <int> <int>\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n```\n\n\n:::\n:::\n\n\n\n16. You can use a `-` before a variable name or a vector of variables to drop them from the data (i.e. <br> `select(-c(year, month, day))`).\n\n## Subset Columns: `select()`\n\nWhat if we want to keep every observation, but only use certain variables? Use `select()`!\n\n\nWe can select columns between variables (inclusive): \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  select(year:day) # <17>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 3\n    year month   day\n   <int> <int> <int>\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n```\n\n\n:::\n:::\n\n\n\n17. Add a `!` before `year` and you'll drop this group of variables from the data. \n\n## Subset Columns: `select()`\n\nWhat if we want to keep every observation, but only use certain variables? Use `select()`!\n\nWe can select columns based on a condition: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  select(where(is.character)) # <18>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 4\n   carrier tailnum origin dest \n   <chr>   <chr>   <chr>  <chr>\n 1 UA      N14228  EWR    IAH  \n 2 UA      N24211  LGA    IAH  \n 3 AA      N619AA  JFK    MIA  \n 4 B6      N804JB  JFK    BQN  \n 5 DL      N668DN  LGA    ATL  \n 6 UA      N39463  EWR    ORD  \n 7 B6      N516JB  EWR    FLL  \n 8 EV      N829AS  LGA    IAD  \n 9 B6      N593JB  JFK    MCO  \n10 AA      N3ALAA  LGA    ORD  \n# ℹ 336,766 more rows\n```\n\n\n:::\n:::\n\n\n\n18. There are a number of helper functions you can use with `select()` including `starts_with()`, `ends_with()`, `contains()` and `num_range()`. Read more about these and more [here](https://tidyselect.r-lib.org/reference/index.html). \n\n## Finding Unique Rows: `distinct()`\n\nYou may want to find the unique combinations of variables in a dataset.  Use `distinct()`\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  distinct(origin, dest) # <19>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 224 × 2\n   origin dest \n   <chr>  <chr>\n 1 EWR    IAH  \n 2 LGA    IAH  \n 3 JFK    MIA  \n 4 JFK    BQN  \n 5 LGA    ATL  \n 6 EWR    ORD  \n 7 EWR    FLL  \n 8 LGA    IAD  \n 9 JFK    MCO  \n10 LGA    ORD  \n# ℹ 214 more rows\n```\n\n\n:::\n:::\n\n\n\n19. Find all unique origin and destination pairs.\n\n## `distinct()` drops variables!\n\nBy default, `distinct()` drops unused variables. If you don't want to drop them, add the argument `.keep_all = TRUE`:\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  distinct(origin, dest, .keep_all = TRUE) # <20> \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 224 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 214 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n20. It’s not a coincidence that all of these distinct flights are on January 1: `distinct()` will find the first occurrence of a unique row in the dataset and discard the rest. Use `count()` if you're looking for the number of occurrences. \n\n## Count Unique Rows: `count()` \n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |>\n  count(origin, dest, sort = TRUE) # <21>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 224 × 3\n   origin dest      n\n   <chr>  <chr> <int>\n 1 JFK    LAX   11262\n 2 LGA    ATL   10263\n 3 LGA    ORD    8857\n 4 JFK    SFO    8204\n 5 LGA    CLT    6168\n 6 EWR    ORD    6100\n 7 JFK    BOS    5898\n 8 LGA    MIA    5781\n 9 JFK    MCO    5464\n10 EWR    BOS    5327\n# ℹ 214 more rows\n```\n\n\n:::\n:::\n\n\n\n21. `sort = TRUE` arranges them in descending order of number of occurrences. \n\n# Modifying data{.section-title background-color=\"#B7A57A\"}\n\n## Sorting Data by Rows: `arrange()`\n\nSometimes it's useful to sort rows in your data, in ascending (low to high) or descending (high to low) order. We do that with `arrange()`.\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  arrange(year, month, day, dep_time) # <22> \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n22. If you provide more than one column name, each additional column will be used to break ties in the values of preceding columns.\n\n## Sorting Data by Rows: `arrange()`\n\nTo sort in descending order, using `desc()` within `arrange()`\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  arrange(desc(dep_delay))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     9      641            900      1301     1242           1530\n 2  2013     6    15     1432           1935      1137     1607           2120\n 3  2013     1    10     1121           1635      1126     1239           1810\n 4  2013     9    20     1139           1845      1014     1457           2210\n 5  2013     7    22      845           1600      1005     1044           1815\n 6  2013     4    10     1100           1900       960     1342           2211\n 7  2013     3    17     2321            810       911      135           1020\n 8  2013     6    27      959           1900       899     1236           2226\n 9  2013     7    22     2257            759       898      121           1026\n10  2013    12     5      756           1700       896     1058           2020\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n## Rename Variables: `rename()`\n\nYou may receive data with unintuitive variable names. Change them using `rename()`.\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  rename(tail_num = tailnum) # <23>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tail_num <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n23. `rename(new_name = old_name)` is the format. You can use `janitor::clean_names()` if you want to automate this process for a lot of variables. \n\n. . . \n\n::: {.callout-caution icon=false}\n## <span style=\"color:tomato\">{{< fa exclamation-triangle >}}</span> Variable Syntax\nI recommend **against** using spaces in a name! It makes things *really hard* sometimes!!\n:::\n\n## Create New Columns: `mutate()`\n\nYou can add new columns to a data frame using `mutate()`. \n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  mutate(\n    gain = dep_delay - arr_delay,\n    speed = distance / air_time * 60,\n    .before = 1 # <24> \n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 21\n    gain speed  year month   day dep_time sched_dep_time dep_delay arr_time\n   <dbl> <dbl> <int> <int> <int>    <int>          <int>     <dbl>    <int>\n 1    -9  370.  2013     1     1      517            515         2      830\n 2   -16  374.  2013     1     1      533            529         4      850\n 3   -31  408.  2013     1     1      542            540         2      923\n 4    17  517.  2013     1     1      544            545        -1     1004\n 5    19  394.  2013     1     1      554            600        -6      812\n 6   -16  288.  2013     1     1      554            558        -4      740\n 7   -24  404.  2013     1     1      555            600        -5      913\n 8    11  259.  2013     1     1      557            600        -3      709\n 9     5  405.  2013     1     1      557            600        -3      838\n10   -10  319.  2013     1     1      558            600        -2      753\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time <int>, arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>,\n#   distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n24. By default, `mutate()` adds new columns on the right hand side of your dataset, which makes it difficult to see if anything happened. You can use the `.before` argument to specify which numeric index (or variable name) to move the newly created variable to. `.after` is an alternative argument for this.   \n\n## Specifying Variables to Keep: `mutate()`\n\nYou can specify which columns to keep with the `.keep` argument:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  mutate(\n    gain = dep_delay - arr_delay,\n    hours = air_time / 60,\n    gain_per_hour = gain / hours,\n    .keep = \"used\" # <25> \n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 6\n   dep_delay arr_delay air_time  gain hours gain_per_hour\n       <dbl>     <dbl>    <dbl> <dbl> <dbl>         <dbl>\n 1         2        11      227    -9 3.78          -2.38\n 2         4        20      227   -16 3.78          -4.23\n 3         2        33      160   -31 2.67         -11.6 \n 4        -1       -18      183    17 3.05           5.57\n 5        -6       -25      116    19 1.93           9.83\n 6        -4        12      150   -16 2.5           -6.4 \n 7        -5        19      158   -24 2.63          -9.11\n 8        -3       -14       53    11 0.883         12.5 \n 9        -3        -8      140     5 2.33           2.14\n10        -2         8      138   -10 2.3           -4.35\n# ℹ 336,766 more rows\n```\n\n\n:::\n:::\n\n\n\n25. \"used\" retains only the variables used to create the new variables, which is useful for checking your work. Other options include: \"all,\" \"unused,\" and \"none.\"\n\n## Move Variables Around: `relocate()`\n\nYou might want to collect related variables together or move important variables to the front. Use `relocate()`!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  relocate(time_hour, air_time) # <26>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n   time_hour           air_time  year month   day dep_time sched_dep_time\n   <dttm>                 <dbl> <int> <int> <int>    <int>          <int>\n 1 2013-01-01 05:00:00      227  2013     1     1      517            515\n 2 2013-01-01 05:00:00      227  2013     1     1      533            529\n 3 2013-01-01 05:00:00      160  2013     1     1      542            540\n 4 2013-01-01 05:00:00      183  2013     1     1      544            545\n 5 2013-01-01 06:00:00      116  2013     1     1      554            600\n 6 2013-01-01 05:00:00      150  2013     1     1      554            558\n 7 2013-01-01 06:00:00      158  2013     1     1      555            600\n 8 2013-01-01 06:00:00       53  2013     1     1      557            600\n 9 2013-01-01 06:00:00      140  2013     1     1      557            600\n10 2013-01-01 06:00:00      138  2013     1     1      558            600\n# ℹ 336,766 more rows\n# ℹ 12 more variables: dep_delay <dbl>, arr_time <int>, sched_arr_time <int>,\n#   arr_delay <dbl>, carrier <chr>, flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, distance <dbl>, hour <dbl>, minute <dbl>\n```\n\n\n:::\n:::\n\n\n\n26. By default `relocate()` moves variables to the front but you can also specify where to put them using the `.before` and `.after` arguments, just like in `mutate()`.\n\n# Summarizing data{.section-title background-color=\"#B7A57A\"}\n\n## Grouping Data: `group_by()`\n\nIf you want to analyze your data by specific groupings, use `group_by()`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  group_by(month) # <27>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n# Groups:   month [12]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n27. `group_by()` doesn’t change the data but you’ll notice that the output indicates that it is “grouped by” month `(Groups: month [12])`. This means subsequent operations will now work “by month”.\n\n## Summarizing Data: `summarize()`\n\n**`summarize()`** calculates summaries of variables in your data:\n\n::: {.incremental}\n* Count the number of rows\n* Calculate the mean\n* Calculate the sum\n* Find the minimum or maximum value\n:::\n\n. . . \n\nYou can use any function inside `summarize()` that aggregates *multiple values* into a *single value* (like `sd()`, `mean()`, or `max()`).\n\n## `summarize()` Example\n\nLet's see what this looks like in our flights dataset:\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  summarize(\n    avg_delay = mean(dep_delay) # <28> \n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  avg_delay\n      <dbl>\n1        NA\n```\n\n\n:::\n:::\n\n\n\n28. The `NA` produced here is a result of calling `mean` on `dep_delay`. Any summarizing function will return `NA` if **any** of the values are `NA`. We can set `na.rm = TRUE` to change this behavior. \n\n## `summarize()` Example\n\nLet's see what this looks like in our flights dataset:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE) \n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  avg_delay\n      <dbl>\n1      12.6\n```\n\n\n:::\n:::\n\n\n\n## Summarizing Data by Groups\n\nWhat if we want to summarize data by our groups? Use `group_by()` **and** `summarize()`\n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  group_by(month) |> \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 × 2\n   month delay\n   <int> <dbl>\n 1     1 10.0 \n 2     2 10.8 \n 3     3 13.2 \n 4     4 13.9 \n 5     5 13.0 \n 6     6 20.8 \n 7     7 21.7 \n 8     8 12.6 \n 9     9  6.72\n10    10  6.24\n11    11  5.44\n12    12 16.6 \n```\n\n\n:::\n:::\n\n\n\n. . . \n\nBecause we did `group_by()` with `month`, then used `summarize()`, we get *one row per value of `month`*!\n\n## Summarizing Data by Groups\n\nYou can create any number of summaries in a single call to summarize().\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  group_by(month) |> \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n() # <29>\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 × 3\n   month delay     n\n   <int> <dbl> <int>\n 1     1 10.0  27004\n 2     2 10.8  24951\n 3     3 13.2  28834\n 4     4 13.9  28330\n 5     5 13.0  28796\n 6     6 20.8  28243\n 7     7 21.7  29425\n 8     8 12.6  29327\n 9     9  6.72 27574\n10    10  6.24 28889\n11    11  5.44 27268\n12    12 16.6  28135\n```\n\n\n:::\n:::\n\n\n\n29. `n()` returns the number of rows in each group. \n\n## Grouping by Multiple Variables <span style=\"color:#B7A57A\">{{< fa scroll >}}</span> {.scrollable} \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily <- flights |> \n  group_by(year, month, day)  \ndaily\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n# Groups:   year, month, day [365]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n. . . \n\n::: {.callout-tip icon=false}\n## <span style=\"color:green\">{{< fa info-circle >}}</span> Summary & Grouping Behavior\nWhen you summarize a tibble grouped by more than one variable, each summary peels off the last group. You can change the default behavior by setting the `.groups` argument to a different value, e.g., \"drop\" to drop all grouping or \"keep\" to preserve the same groups. The default is \"drop_last\". \n:::\n\n## Remove Grouping: `ungroup()`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily |> \n  ungroup() \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n## New Alternative for Grouping: `.by`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n(),\n    .by = month # <30>\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 × 3\n   month delay     n\n   <int> <dbl> <int>\n 1     1 10.0  27004\n 2    10  6.24 28889\n 3    11  5.44 27268\n 4    12 16.6  28135\n 5     2 10.8  24951\n 6     3 13.2  28834\n 7     4 13.9  28330\n 8     5 13.0  28796\n 9     6 20.8  28243\n10     7 21.7  29425\n11     8 12.6  29327\n12     9  6.72 27574\n```\n\n\n:::\n:::\n\n\n\n30. `.by` works with all verbs and has the advantage that you don’t need to use the `.groups` argument to suppress the grouping message or `ungroup()` when you’re done.\n\n## Select Specific Rows Per Group: `slice_*`\n\nThere are five handy functions that allow you extract specific rows within each group:\n\n::: {.incremental}\n* `df |> slice_head(n = 1)` takes the first row from each group.\n* `df |> slice_tail(n = 1)` takes the last row in each group.\n* `df |> slice_min(x, n = 1)` takes the row with the smallest value of column x.\n* `df |> slice_max(x, n = 1)` takes the row with the largest value of column x.\n* `df |> slice_sample(n = 1)` takes one random row.\n:::\n\n. . . \n\nLet's find the flights that are most delayed upon arrival at each destination. \n\n\n## Select Specific Rows Per Group: `slice_*` \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  group_by(dest) |> \n  slice_max(arr_delay, n = 1) |> # <31>\n  relocate(dest) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 108 × 19\n# Groups:   dest [105]\n   dest   year month   day dep_time sched_dep_time dep_delay arr_time\n   <chr> <int> <int> <int>    <int>          <int>     <dbl>    <int>\n 1 ABQ    2013     7    22     2145           2007        98      132\n 2 ACK    2013     7    23     1139            800       219     1250\n 3 ALB    2013     1    25      123           2000       323      229\n 4 ANC    2013     8    17     1740           1625        75     2042\n 5 ATL    2013     7    22     2257            759       898      121\n 6 AUS    2013     7    10     2056           1505       351     2347\n 7 AVL    2013     8    13     1156            832       204     1417\n 8 BDL    2013     2    21     1728           1316       252     1839\n 9 BGR    2013    12     1     1504           1056       248     1628\n10 BHM    2013     4    10       25           1900       325      136\n# ℹ 98 more rows\n# ℹ 11 more variables: sched_arr_time <int>, arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n31. You can vary `n` to select more than one row, or instead of `n =`, you can use `prop = 0.1` to select (e.g.) 10% of the rows in each group.\n\n::: aside\nThere are 105 groups but 108 rows! Why? `slice_min()` and `slice_max()` keep tied values so `n = 1` means \"give us all rows with the highest value.\" If you want exactly one row per group you can set `with_ties = FALSE`.\n:::\n\n# Merging Data {.section-title background-color=\"#4B2E83\"}\n\n## Why Merge Data?\n\nIn practice, we often collect data from different sources. To analyze the data, we usually must first combine (merge) them.\n\n. . . \n\nFor example, imagine you would like to study county-level patterns with respect to age and grocery spending. However, you can only find,\n\n* County level age data from the US Census, and \n* County level grocery spending data from the US Department of Agriculture\n\n. . . \n\nMerge the data!!\n\n. . . \n\nTo do this we'll be using the various **join** functions from the `dplyr` package. \n\n## Joining in Concept\n\nWe need to think about the following when we want to merge data frames A and B:\n\n::: {.fragment}\n* Which rows are we keeping from each data frame?\n:::\n\n::: {.fragment}\n* Which columns are we keeping from each data frame?\n:::\n\n::: {.fragment .fade-in}\n::: {.fragment .highlight-red}\n* Which variables determine whether rows match?\n:::\n:::\n\n## Keys\n\nKeys are the way that two datasets are connected to one another. The two types of keys are: \n\n::: {.incremental}\n1. **Primary**: a variable or set of variables that uniquely identifies each observation.\n    i) When more than one variable makes up the primary key it's called a **compound key**\n2. **Foreign**: a variable (or set of variables) that corresponds to a primary key in another table.\n:::\n\n## Primary Keys <span style=\"color:#B7A57A\">{{< fa scroll >}}</span> {.scrollable} \n\nLet's look at our data to gain a better sense of what this all means. \n\n::: {.panel-tabset}\n\n### `airlines` \n\n::: {.smaller-font}\n`airlines` records two pieces of data about each airline: its carrier code and its full name. You can identify an airline with its two letter carrier code, making `carrier` the primary key.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairlines \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 16 × 2\n   carrier name                       \n   <chr>   <chr>                      \n 1 9E      Endeavor Air Inc.          \n 2 AA      American Airlines Inc.     \n 3 AS      Alaska Airlines Inc.       \n 4 B6      JetBlue Airways            \n 5 DL      Delta Air Lines Inc.       \n 6 EV      ExpressJet Airlines Inc.   \n 7 F9      Frontier Airlines Inc.     \n 8 FL      AirTran Airways Corporation\n 9 HA      Hawaiian Airlines Inc.     \n10 MQ      Envoy Air                  \n11 OO      SkyWest Airlines Inc.      \n12 UA      United Air Lines Inc.      \n13 US      US Airways Inc.            \n14 VX      Virgin America             \n15 WN      Southwest Airlines Co.     \n16 YV      Mesa Airlines Inc.         \n```\n\n\n:::\n:::\n\n\n\n### `airports`\n\n::: {.smaller-font}\n`airports` records data about each airport. You can identify each airport by its three letter airport code, making `faa` the primary key.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairports\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,458 × 8\n   faa   name                             lat    lon   alt    tz dst   tzone    \n   <chr> <chr>                          <dbl>  <dbl> <dbl> <dbl> <chr> <chr>    \n 1 04G   Lansdowne Airport               41.1  -80.6  1044    -5 A     America/…\n 2 06A   Moton Field Municipal Airport   32.5  -85.7   264    -6 A     America/…\n 3 06C   Schaumburg Regional             42.0  -88.1   801    -6 A     America/…\n 4 06N   Randall Airport                 41.4  -74.4   523    -5 A     America/…\n 5 09J   Jekyll Island Airport           31.1  -81.4    11    -5 A     America/…\n 6 0A9   Elizabethton Municipal Airport  36.4  -82.2  1593    -5 A     America/…\n 7 0G6   Williams County Airport         41.5  -84.5   730    -5 A     America/…\n 8 0G7   Finger Lakes Regional Airport   42.9  -76.8   492    -5 A     America/…\n 9 0P2   Shoestring Aviation Airfield    39.8  -76.6  1000    -5 U     America/…\n10 0S9   Jefferson County Intl           48.1 -123.    108    -8 A     America/…\n# ℹ 1,448 more rows\n```\n\n\n:::\n:::\n\n\n\n\n### `planes`\n\n::: {.smaller-font}\n`planes` records data about each plane. You can identify a plane by its tail number, making `tailnum` the primary key.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplanes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3,322 × 9\n   tailnum  year type              manufacturer model engines seats speed engine\n   <chr>   <int> <chr>             <chr>        <chr>   <int> <int> <int> <chr> \n 1 N10156   2004 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 2 N102UW   1998 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 3 N103US   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 4 N104UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 5 N10575   2002 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 6 N105UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 7 N107US   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 8 N108UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 9 N109UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n10 N110UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n# ℹ 3,312 more rows\n```\n\n\n:::\n:::\n\n\n\n\n### `weather`\n\n::: {.smaller-font}\n`weather` records data about the weather at the origin airports. You can identify each observation by the combination of location and time, making `origin` and `time_hour` the compound primary key.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 26,115 × 15\n   origin  year month   day  hour  temp  dewp humid wind_dir wind_speed\n   <chr>  <int> <int> <int> <int> <dbl> <dbl> <dbl>    <dbl>      <dbl>\n 1 EWR     2013     1     1     1  39.0  26.1  59.4      270      10.4 \n 2 EWR     2013     1     1     2  39.0  27.0  61.6      250       8.06\n 3 EWR     2013     1     1     3  39.0  28.0  64.4      240      11.5 \n 4 EWR     2013     1     1     4  39.9  28.0  62.2      250      12.7 \n 5 EWR     2013     1     1     5  39.0  28.0  64.4      260      12.7 \n 6 EWR     2013     1     1     6  37.9  28.0  67.2      240      11.5 \n 7 EWR     2013     1     1     7  39.0  28.0  64.4      240      15.0 \n 8 EWR     2013     1     1     8  39.9  28.0  62.2      250      10.4 \n 9 EWR     2013     1     1     9  39.9  28.0  62.2      260      15.0 \n10 EWR     2013     1     1    10  41    28.0  59.6      260      13.8 \n# ℹ 26,105 more rows\n# ℹ 5 more variables: wind_gust <dbl>, precip <dbl>, pressure <dbl>,\n#   visib <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n### `flights`\n\n::: {.smaller-font}\n`flights` has three variables (`time_hour`, `flight`, `carrier`) that uniquely identify an observation. More significantly, however, it contains **foreign keys** that correspond to the primary keys of the other datasets.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n:::\n\n\n## Foreign Keys\n\n![Note: grey shading indicates the primary key for that particular dataset.](images/relational.png){fig-align=\"center\"}\n\n::: {.incremental}\n* `flights$origin` --> `airports$faa`\n* `flights$dest` --> `airports$faa`\n* `flights$origin`-`flights$time_hour` --> `weather$origin`-`weather$time_hour`.\n* `flights$tailnum` --> `planes$tailnum`\n* `flights$carrier` --> `airlines$carrier`\n:::\n\n## Checking Keys\n\nA nice feature of these data are that the primary and foreign keys have the same name and almost every variable name used across multiple tables has the same meaning.^[With the exception of `year`: it means year of departure in `flights` and year of manufacture in `planes`. ] This isn't always the case!^[We'll cover how to handle this shortly.]\n\n. . . \n\nIt is good practice to make sure your primary keys actually uniquely identify an observation and that they don't have any missing values. \n\n. . . \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nplanes |> \n  count(tailnum) |> # <1>\n  filter(n > 1) # <1> \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 0 × 2\n# ℹ 2 variables: tailnum <chr>, n <int>\n```\n\n\n:::\n:::\n\n\n\n1. If your primary keys uniquely identify each observation you'll get an empty tibble in return. \n\n. . . \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplanes |> \n  filter(is.na(tailnum)) # <2>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 0 × 9\n# ℹ 9 variables: tailnum <chr>, year <int>, type <chr>, manufacturer <chr>,\n#   model <chr>, engines <int>, seats <int>, speed <int>, engine <chr>\n```\n\n\n:::\n:::\n\n\n\n2. If none of your primary keys are missing you'll get an empty tibble in return here too. \n\n## Surrogate Keys\n\nSometimes you'll want to create an index of your observations to serve as a surrogate key because the compound primary key is not particlarly easy to reference. \n\n. . . \n\nFor example, our `flights` dataset has three variables that uniquely identify each observation: `time_hour`, `carrier`, `flight`.\n\n. . . \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nflights2 <- flights |> \n  mutate(id = row_number(), .before = 1) # <3> \nflights2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 20\n      id  year month   day dep_time sched_dep_time dep_delay arr_time\n   <int> <int> <int> <int>    <int>          <int>     <dbl>    <int>\n 1     1  2013     1     1      517            515         2      830\n 2     2  2013     1     1      533            529         4      850\n 3     3  2013     1     1      542            540         2      923\n 4     4  2013     1     1      544            545        -1     1004\n 5     5  2013     1     1      554            600        -6      812\n 6     6  2013     1     1      554            558        -4      740\n 7     7  2013     1     1      555            600        -5      913\n 8     8  2013     1     1      557            600        -3      709\n 9     9  2013     1     1      557            600        -3      838\n10    10  2013     1     1      558            600        -2      753\n# ℹ 336,766 more rows\n# ℹ 12 more variables: sched_arr_time <int>, arr_delay <dbl>, carrier <chr>,\n#   flight <int>, tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>,\n#   distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>\n```\n\n\n:::\n:::\n\n\n\n3. `row_number()` simply specifies the row number of the dataframe. \n\n## Basic (Equi-) Joins\n\nAll join functions have the same basic interface: they take a **pair** of data frames and return **one** data frame. \n\n. . . \n\nThe order of the rows and columns is primarily going to be determined by the first data frame. \n\n. . . \n\n`dplyr` has two types of joins: *mutating* and *filtering.* \n\n<br>\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {.fragment}\n#### Mutating Joins \nAdd new variables to one data frame from matching observations from another data frame. \n\n* `left_join()`\n* `right_join()`\n* `inner_join()`\n* `full_join()`\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.fragment}\n#### Filtering Joins \nFilter observations from one data frame based on whether or not they match an observation in another data frame. \n\n* `semi_join()`\n* `anti-join()`\n:::\n\n:::\n\n::::\n\n## `Mutating Joins`\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n::: {.fragment}\n![](images/joins_setup.png)\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n::: {.fragment}\n![](images/joins_setup2.png)\n:::\n:::\n\n::::\n\n## `left_join()` <span style=\"color:#B7A57A\">{{< fa scroll >}}</span> {.scrollable} \n\n![](images/joins_left.png){fig-align=\"center\"}\n\n::: aside\n::: {.incremental}\n* The most common type of join\n* Appends columns from `y` to `x` by the rows in `x`\n    + `NA` added if there is nothing from `y`\n* Natural join: when all variables that appear in both datasets are used as the join key\n    + If the join_by() argument is not specified, `left_join()` will automatically join by all columns that have names and values in common. \n:::\n:::\n\n## `left_join` in `nycflights13`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights2 <- flights |> \n  select(year, time_hour, origin, dest, tailnum, carrier)\n```\n:::\n\n\n\nWith only the pertinent variables from the `flights` dataset, we can see how a `left_join` works with the `airlines` dataset. \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nflights2 |>\n  left_join(airlines)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(carrier)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 7\n    year time_hour           origin dest  tailnum carrier name                  \n   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr>                 \n 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      United Air Lines Inc. \n 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      United Air Lines Inc. \n 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      American Airlines Inc.\n 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      JetBlue Airways       \n 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Delta Air Lines Inc.  \n 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      United Air Lines Inc. \n 7  2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6      JetBlue Airways       \n 8  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV      ExpressJet Airlines I…\n 9  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6      JetBlue Airways       \n10  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      American Airlines Inc.\n# ℹ 336,766 more rows\n```\n\n\n:::\n:::\n\n\n\n## Different variable meanings\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nflights2 |> \n  left_join(planes)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(year, tailnum)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 13\n    year time_hour           origin dest  tailnum carrier type  manufacturer\n   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr> <chr>       \n 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      <NA>  <NA>        \n 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      <NA>  <NA>        \n 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      <NA>  <NA>        \n 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      <NA>  <NA>        \n 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      <NA>  <NA>        \n 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      <NA>  <NA>        \n 7  2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6      <NA>  <NA>        \n 8  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV      <NA>  <NA>        \n 9  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6      <NA>  <NA>        \n10  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      <NA>  <NA>        \n# ℹ 336,766 more rows\n# ℹ 5 more variables: model <chr>, engines <int>, seats <int>, speed <int>,\n#   engine <chr>\n```\n\n\n:::\n:::\n\n\n\n. . . \n\nWhen we try to do this, however, we get a bunch of `NA`s. Why? \n\n## Different variable meanings\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights2 |> \n  left_join(planes)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(year, tailnum)`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 13\n    year time_hour           origin dest  tailnum carrier type  manufacturer\n   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr> <chr>       \n 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      <NA>  <NA>        \n 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      <NA>  <NA>        \n 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      <NA>  <NA>        \n 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      <NA>  <NA>        \n 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      <NA>  <NA>        \n 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      <NA>  <NA>        \n 7  2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6      <NA>  <NA>        \n 8  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV      <NA>  <NA>        \n 9  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6      <NA>  <NA>        \n10  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      <NA>  <NA>        \n# ℹ 336,766 more rows\n# ℹ 5 more variables: model <chr>, engines <int>, seats <int>, speed <int>,\n#   engine <chr>\n```\n\n\n:::\n:::\n\n\n\n*Join is trying to use tailnum and year as a compound key.* While both datasets have `year` as a variable, they mean different things. Therefore, we need to be explicit here about what to join by. \n\n## Different variable meanings\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nflights2 |> \n  left_join(planes, join_by(tailnum)) # <4>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 14\n   year.x time_hour           origin dest  tailnum carrier year.y type          \n    <int> <dttm>              <chr>  <chr> <chr>   <chr>    <int> <chr>         \n 1   2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA        1999 Fixed wing mu…\n 2   2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA        1998 Fixed wing mu…\n 3   2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA        1990 Fixed wing mu…\n 4   2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6        2012 Fixed wing mu…\n 5   2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL        1991 Fixed wing mu…\n 6   2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA        2012 Fixed wing mu…\n 7   2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6        2000 Fixed wing mu…\n 8   2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV        1998 Fixed wing mu…\n 9   2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6        2004 Fixed wing mu…\n10   2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA          NA <NA>          \n# ℹ 336,766 more rows\n# ℹ 6 more variables: manufacturer <chr>, model <chr>, engines <int>,\n#   seats <int>, speed <int>, engine <chr>\n```\n\n\n:::\n:::\n\n\n\n4. `join_by(tailnum)` is short for `join_by(tailnum == tailnum)` making these types of basic joins equi joins. \n\n::: aside\nWhen you have the same variable name but they mean different things you can specify a particular suffix with the `suffix` argument.\n:::\n\n## Different variable names\n\nIf you have keys that have the same meaning (values) but are named different things in their respective datasets you'd also specify that with `join_by()`\n\n. . . \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nflights2 |> \n  left_join(airports, join_by(dest == faa)) # <5>\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 13\n    year time_hour           origin dest  tailnum carrier name         lat   lon\n   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr>      <dbl> <dbl>\n 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      George Bu…  30.0 -95.3\n 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      George Bu…  30.0 -95.3\n 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Miami Intl  25.8 -80.3\n 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      <NA>        NA    NA  \n 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Hartsfiel…  33.6 -84.4\n 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Chicago O…  42.0 -87.9\n 7  2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6      Fort Laud…  26.1 -80.2\n 8  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV      Washingto…  38.9 -77.5\n 9  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6      Orlando I…  28.4 -81.3\n10  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      Chicago O…  42.0 -87.9\n# ℹ 336,766 more rows\n# ℹ 4 more variables: alt <dbl>, tz <dbl>, dst <chr>, tzone <chr>\n```\n\n\n:::\n:::\n\n\n\n5. `by = c(\"dest\" = \"faa\")` was the former syntax for this and you still might see that in older code. \n\n. . . \n\nThis will match `dest` to `faa` for the join and then drop `faa`. \n\n## Different variable names\n\nYou can request `dplyr` to keep both keys with `keep = TRUE` argument. \n\n. . . \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nflights2 |> \n  left_join(airports, join_by(dest == faa), keep = TRUE) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 336,776 × 14\n    year time_hour           origin dest  tailnum carrier faa   name         lat\n   <int> <dttm>              <chr>  <chr> <chr>   <chr>   <chr> <chr>      <dbl>\n 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      IAH   George Bu…  30.0\n 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      IAH   George Bu…  30.0\n 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      MIA   Miami Intl  25.8\n 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      <NA>  <NA>        NA  \n 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      ATL   Hartsfiel…  33.6\n 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      ORD   Chicago O…  42.0\n 7  2013 2013-01-01 06:00:00 EWR    FLL   N516JB  B6      FLL   Fort Laud…  26.1\n 8  2013 2013-01-01 06:00:00 LGA    IAD   N829AS  EV      IAD   Washingto…  38.9\n 9  2013 2013-01-01 06:00:00 JFK    MCO   N593JB  B6      MCO   Orlando I…  28.4\n10  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      ORD   Chicago O…  42.0\n# ℹ 336,766 more rows\n# ℹ 5 more variables: lon <dbl>, alt <dbl>, tz <dbl>, dst <chr>, tzone <chr>\n```\n\n\n:::\n:::\n\n\n\n## `right_join()`\n\n![Has the same interface as a left_join but keeps all rows in `y` instead of `x`](images/joins_right.png){fig-align=\"center\"}\n\n## `inner_join()`\n\n![Has the same interface as a left_join but only keeps rows that occur in both x and y](images/joins_inner.png){fig-align=\"center\"}\n\n## `full_join()`\n\n![Has the same interface as a left_join but keeps all rows in either x or y](images/joins_full.png){fig-align=\"center\"}\n\n## `Filtering Joins`\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n<br>\n\n::: {.fragment}\n![](images/joins_setup.png)\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n<br>\n\n::: {.fragment}\n![](images/joins_setup2.png)\n:::\n:::\n\n::::\n\n## `semi_join()`\n\n![Keeps all rows in x that have a match in y](images/joins_semi.png){fig-align=\"center\"}\n\n\n## `semi_join()` in `nycflights13`\n\nWe could use a semi-join to filter the airports dataset to show just the origin airports.\n\n. . . \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nairports |> \n  semi_join(flights2, join_by(faa == origin))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 8\n  faa   name                  lat   lon   alt    tz dst   tzone           \n  <chr> <chr>               <dbl> <dbl> <dbl> <dbl> <chr> <chr>           \n1 EWR   Newark Liberty Intl  40.7 -74.2    18    -5 A     America/New_York\n2 JFK   John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n3 LGA   La Guardia           40.8 -73.9    22    -5 A     America/New_York\n```\n\n\n:::\n:::\n\n\n\n\n## `anti_join()`\n\n![Returns all rows in x that don’t have a match in y](images/joins_anti.png){fig-align=\"center\"}\n\n## `anti_join()` in `nycflights13`\n\nWe can find rows that are missing from airports by looking for flights that don’t have a matching destination airport.\n\n. . . \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nairports |> \n  anti_join(flights2, join_by(faa == origin))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,455 × 8\n   faa   name                             lat    lon   alt    tz dst   tzone    \n   <chr> <chr>                          <dbl>  <dbl> <dbl> <dbl> <chr> <chr>    \n 1 04G   Lansdowne Airport               41.1  -80.6  1044    -5 A     America/…\n 2 06A   Moton Field Municipal Airport   32.5  -85.7   264    -6 A     America/…\n 3 06C   Schaumburg Regional             42.0  -88.1   801    -6 A     America/…\n 4 06N   Randall Airport                 41.4  -74.4   523    -5 A     America/…\n 5 09J   Jekyll Island Airport           31.1  -81.4    11    -5 A     America/…\n 6 0A9   Elizabethton Municipal Airport  36.4  -82.2  1593    -5 A     America/…\n 7 0G6   Williams County Airport         41.5  -84.5   730    -5 A     America/…\n 8 0G7   Finger Lakes Regional Airport   42.9  -76.8   492    -5 A     America/…\n 9 0P2   Shoestring Aviation Airfield    39.8  -76.6  1000    -5 U     America/…\n10 0S9   Jefferson County Intl           48.1 -123.    108    -8 A     America/…\n# ℹ 1,445 more rows\n```\n\n\n:::\n:::\n\n\n\n::: aside\nThis type of join is useful for finding missing values that are implicit in the data (i.e. `NA`s that don't show up in the data but only exist as an absence.)\n:::\n\n## More Than One Match\n\n![](images/joins_match-types.png){fig-align=\"center\"}\n\n. . . \n\nThere are three possible outcomes for a row in x:\n\n::: {.incremental}\n* If it doesn’t match anything, it’s dropped.\n* If it matches 1 row in y, it’s preserved.\n* If it matches more than 1 row in y, it’s duplicated once for each match.\n:::\n\n. . . \n\nWhat happens if we match on more than one row? \n\n## More Than One Match\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\ndf1 <- tibble(key = c(1, 2, 2), val_x = c(\"x1\", \"x2\", \"x3\"))\ndf2 <- tibble(key = c(1, 2, 2), val_y = c(\"y1\", \"y2\", \"y3\"))\n\ndf1 |> \n  inner_join(df2, join_by(key))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in inner_join(df1, df2, join_by(key)): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 2 of `x` matches multiple rows in `y`.\nℹ Row 2 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n    key val_x val_y\n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     2 x2    y3   \n4     2 x3    y2   \n5     2 x3    y3   \n```\n\n\n:::\n:::\n\n\n\n\n. . . \n\nIf you're doing this deliberately, set relationship = \"many-to-many\", as the warning suggests.\n\n::: aside\nGiven their nature, filtering joins never duplicate rows like mutating joins do. They will only ever return a subset of the datasets.\n:::\n\n## Non-Equi Joins\n\nThe joins we've discussed thus far have all been equi-joins, where the rows match if the x key equals the y key. But you can also specify other types of relationships. \n\n. . . \n\n`dplyr` has four different types of non-equi joins: \n\n. . . \n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n* **Cross joins** match every pair of rows.\n:::\n\n::: {.column width=\"50%\"}\n\n![](images/joins_cross.png){width=25% .absolute top=150 right=150}\n\n:::\n::::\n\n::: aside\nCross joins, aka self-joins, are useful when generating permutations (e.g. creating every possible combination of values). This comes in handy when creating datasets of predicted probabilities for plotting in ggplot. \n:::\n\n## Non-Equi Joins\n\nThe joins we've discussed thus far have all been equi-joins, where the rows match if the x key equals the y key. But you can also specify other types of relationships. \n\n`dplyr` has four different types of non-equi joins: \n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n* **Cross joins** match every pair of rows.\n* **Inequality joins** use <, <=, >, and >= instead of ==.\n    * **Overlap joins** are a special type of inequality join designed to work with ranges^[Overlap joins provide three helpers that use inequality joins to make it easier to work with intervals: `between()`, `within()`, `overlaps()`. Read more about their functionality and specifications [here](https://dplyr.tidyverse.org/reference/join_by.html?q=within#overlap-joins).].\n\n:::\n\n::: {.column width=\"50%\"}\n![](images/joins_inequality.png){width=30% .absolute top=158 right=120}\n:::\n::::\n\n::: aside\nInequality joins can be used to restrict the cross join so that instead of generating all permutations, we generate all combinations.\n:::\n\n## Non-Equi Joins\n\nThe joins we've discussed thus far have all been equi-joins, where the rows match if the x key equals the y key. But you can also specify other types of relationships. \n\n`dplyr` has four different types of non-equi joins: \n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n* **Cross joins** match every pair of rows.\n* **Inequality joins** use <, <=, >, and >= instead of ==.\n    * **Overlap joins** are a special type of inequality join designed to work with ranges.\n* **Rolling joins** are similar to inequality joins but only find the closest match.\n\n:::\n\n::: {.column width=\"50%\"}\n![](images/joins_rolling.png){width=42% .absolute top=155 right=35}\n:::\n::::\n\n::: aside\nRolling joins are a special type of inequality join where instead of getting every row that satisfies the inequality, you get just the closest row. You can turn any inequality join into a rolling join by adding closest().\n:::\n\n# Tidying and Reshaping Data {.section-title background-color=\"#4B2E83\"}\n\n# {data-menu-title=\"`tidyr`\" background-image=\"images/tidyr.png\" background-size=\"contain\" background-position=\"center\" .section-title background-color=\"#B7A57A\"}\n\n## What is Tidy Data\n\n**Tidy data^[Read the original article [here](https://www.jstatsoft.org/article/view/v059i10).]** (aka \"long data\") are such that:\n\n![](images/tidy-1.png){fig-align=\"center\"}\n\n::: {.incremental}\n1. The values for a single variable are in their own column.\n2. The values for a single observation are in their own row.\n3. There is only one value per cell.\n:::\n\n## Why do we Want Tidy Data?\n\n::: {.incremental}\n* **Easier to understand** many rows than many columns^[Placing variables in columns also leverages `R`'s vectorized nature, i.e. most built-in `R` functions work with values of vectors.]\n* Required for **plotting** in `ggplot2`^[In fact, all tidyverse functions are designed to work with tidy data.]\n* Required for many types of **statistical procedures** (e.g. hierarchical or mixed effects models)\n* Fewer issues with **missing values and \"imbalanced\"** repeated measures data\n* Having a consistent method for storing data means it's easier to learn the tools to work with it since there's an underlying uniformity.\n:::\n\n. . . \n\nMost real-world data is not tidy because data are often organized for goals other than analysis (i.e. data entry) and most people aren't familiar with the principles of tidy data. \n\n## Slightly \"Messy\" Data\n\n::::{.columns}\n:::{.column width=\"60%\"}\n\n| **Program**     | **First Year** | **Second Year** |\n|-----------------|-----------:|---------:|\n| Evans School    |     10     |    6    |\n| Arts & Sciences |      5     |    6    |\n| Public Health   |      2     |    3    |\n| Other           |      5     |    1    |\n\n:::\n:::{.column width=\"40%\"}\n\n* What is an **observation**?\n    + A group of students from a program of a given year\n    \n\n* What are the **variables**?\n    + Program, Year\n\n\n* What are the **values**?\n    + Program: Evans School, Arts & Sciences, Public Health, Other\n    + Year: First, Second -- **in column headings. Bad!**\n    + Count: **spread over two columns!**\n:::\n::::\n\n## Tidy Version\n\n::::{.columns}\n:::{.column width=\"50%\"}\n\n| **Program**     | **Year** | **Count** |\n|-----------------|-----------:|---------:|\n| Evans School    |     First |    10   |\n| Evans School    |     Second   |    6    |\n| Arts & Sciences |     First |    5    |\n| Arts & Sciences |     Second   |    6    |\n| Public Health   |     First |    2    |\n| Public Health   |     Second   |    3    |\n| Other           |     First |    5    |\n| Other           |     Second   |    1    |\n:::\n:::{.column width=\"50%\"}\n* Each variable is a column.\n\n* Each observation is a row.\n\n* Each cell has a single value.\n:::\n::::\n\n## Billboard Data\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 317\nColumns: 81\n$ year         <int> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 200…\n$ artist       <chr> \"2 Pac\", \"2Ge+her\", \"3 Doors Down\", \"3 Doors Down\", \"504 …\n$ track        <chr> \"Baby Don't Cry (Keep...\", \"The Hardest Part Of ...\", \"Kr…\n$ time         <time> 04:22:00, 03:15:00, 03:53:00, 04:24:00, 03:35:00, 03:24:…\n$ date.entered <date> 2000-02-26, 2000-09-02, 2000-04-08, 2000-10-21, 2000-04-…\n$ wk1          <int> 87, 91, 81, 76, 57, 51, 97, 84, 59, 76, 84, 57, 50, 71, 7…\n$ wk2          <int> 82, 87, 70, 76, 34, 39, 97, 62, 53, 76, 84, 47, 39, 51, 6…\n$ wk3          <int> 72, 92, 68, 72, 25, 34, 96, 51, 38, 74, 75, 45, 30, 28, 5…\n$ wk4          <int> 77, NA, 67, 69, 17, 26, 95, 41, 28, 69, 73, 29, 28, 18, 4…\n$ wk5          <int> 87, NA, 66, 67, 17, 26, 100, 38, 21, 68, 73, 23, 21, 13, …\n$ wk6          <int> 94, NA, 57, 65, 31, 19, NA, 35, 18, 67, 69, 18, 19, 13, 3…\n$ wk7          <int> 99, NA, 54, 55, 36, 2, NA, 35, 16, 61, 68, 11, 20, 11, 34…\n$ wk8          <int> NA, NA, 53, 59, 49, 2, NA, 38, 14, 58, 65, 9, 17, 1, 29, …\n$ wk9          <int> NA, NA, 51, 62, 53, 3, NA, 38, 12, 57, 73, 9, 17, 1, 27, …\n$ wk10         <int> NA, NA, 51, 61, 57, 6, NA, 36, 10, 59, 83, 11, 17, 2, 30,…\n$ wk11         <int> NA, NA, 51, 61, 64, 7, NA, 37, 9, 66, 92, 1, 17, 2, 36, N…\n$ wk12         <int> NA, NA, 51, 59, 70, 22, NA, 37, 8, 68, NA, 1, 3, 3, 37, N…\n$ wk13         <int> NA, NA, 47, 61, 75, 29, NA, 38, 6, 61, NA, 1, 3, 3, 39, N…\n$ wk14         <int> NA, NA, 44, 66, 76, 36, NA, 49, 1, 67, NA, 1, 7, 4, 49, N…\n$ wk15         <int> NA, NA, 38, 72, 78, 47, NA, 61, 2, 59, NA, 4, 10, 12, 57,…\n$ wk16         <int> NA, NA, 28, 76, 85, 67, NA, 63, 2, 63, NA, 8, 17, 11, 63,…\n$ wk17         <int> NA, NA, 22, 75, 92, 66, NA, 62, 2, 67, NA, 12, 25, 13, 65…\n$ wk18         <int> NA, NA, 18, 67, 96, 84, NA, 67, 2, 71, NA, 22, 29, 15, 68…\n$ wk19         <int> NA, NA, 18, 73, NA, 93, NA, 83, 3, 79, NA, 23, 29, 18, 79…\n$ wk20         <int> NA, NA, 14, 70, NA, 94, NA, 86, 4, 89, NA, 43, 40, 20, 86…\n$ wk21         <int> NA, NA, 12, NA, NA, NA, NA, NA, 5, NA, NA, 44, 43, 30, NA…\n$ wk22         <int> NA, NA, 7, NA, NA, NA, NA, NA, 5, NA, NA, NA, 50, 40, NA,…\n$ wk23         <int> NA, NA, 6, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, 39, NA,…\n$ wk24         <int> NA, NA, 6, NA, NA, NA, NA, NA, 9, NA, NA, NA, NA, 44, NA,…\n$ wk25         <int> NA, NA, 6, NA, NA, NA, NA, NA, 13, NA, NA, NA, NA, NA, NA…\n$ wk26         <int> NA, NA, 5, NA, NA, NA, NA, NA, 14, NA, NA, NA, NA, NA, NA…\n$ wk27         <int> NA, NA, 5, NA, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA, NA…\n$ wk28         <int> NA, NA, 4, NA, NA, NA, NA, NA, 23, NA, NA, NA, NA, NA, NA…\n$ wk29         <int> NA, NA, 4, NA, NA, NA, NA, NA, 22, NA, NA, NA, NA, NA, NA…\n$ wk30         <int> NA, NA, 4, NA, NA, NA, NA, NA, 33, NA, NA, NA, NA, NA, NA…\n$ wk31         <int> NA, NA, 4, NA, NA, NA, NA, NA, 36, NA, NA, NA, NA, NA, NA…\n$ wk32         <int> NA, NA, 3, NA, NA, NA, NA, NA, 43, NA, NA, NA, NA, NA, NA…\n$ wk33         <int> NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk34         <int> NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk35         <int> NA, NA, 4, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk36         <int> NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk37         <int> NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk38         <int> NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk39         <int> NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk40         <int> NA, NA, 15, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk41         <int> NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk42         <int> NA, NA, 13, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk43         <int> NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk44         <int> NA, NA, 16, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk45         <int> NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk46         <int> NA, NA, 21, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk47         <int> NA, NA, 22, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk48         <int> NA, NA, 24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk49         <int> NA, NA, 28, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk50         <int> NA, NA, 33, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk51         <int> NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk52         <int> NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk53         <int> NA, NA, 49, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk54         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk55         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk56         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk57         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk58         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk59         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk60         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk61         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk62         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk63         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk64         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk65         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk66         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk67         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk68         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk69         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk70         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk71         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk72         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk73         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk74         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk75         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk76         <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n```\n\n\n:::\n:::\n\n\n\n. . . \n\n\\\n\nThis data is just ugly-messy!\n\n::: aside\nWeek columns continue up to `wk76`!\n:::\n\n## How is Billboard currently organized?\n\n::: {.incremental}\n* What are the **observations** in the data?\n    + Song on the Billboard chart each week\n* What are the **variables** in the data?\n    + Year, artist, track, song length, date entered Hot 100, week since first entered Hot 100 (**spread over many columns**), rank during week (**spread over many columns**)\n* What are the **values** in the data?\n    + e.g. 2000; 3 Doors Down; Kryptonite; 3 minutes 53 seconds; April 8, 2000; Week 3 (**stuck in column headings**); rank 68 (**spread over many columns**)\n:::\n\n## `tidyr`\n\nThe `tidyr` package provides functions to tidy up data. \n\n. . . \n\n**Key functions:**\n\n* **`pivot_longer()`**: takes a set of columns and pivots them down (\"longer\") to make two new columns (which you can name yourself): \n    * A `name` column that stores the original column names\n    * A `value` with the values in those original columns\n\n. . . \n\n* **`pivot_wider()`**: inverts `pivot_longer()` by taking two columns and pivoting them up and across (\"wider\") into multiple columns\n\n## `pivot_longer()`\n\nThis function usually takes three arguments:\n\n::: {.incremental}\n1. `cols`: The columns that need to be pivoted (are not variables)\n2. `names_to`: Names the new variable that is stored in multiple columns\n3. `values_to`: Names the variable stored in the cell values\n:::\n\n## `pivot_longer()`\n\nThis function usually takes three arguments:\n\n1. `cols`: The columns that need to be pivoted (are not variables)\n2. **`names_to`: Names the new variable that is stored in multiple columns**\n3. `values_to`: Names the variable stored in the cell values\n\n![](images/pivot_longer2_column_names.png){fig-align=\"center\"}\n\n## `pivot_longer()`\n\nThis function usually takes three arguments:\n\n1. `cols`: The columns that need to be pivoted (are not variables)\n2. `names_to`: Names the new variable that is stored in multiple columns\n3. **`values_to`: Names the variable stored in the cell values**\n\n![](images/pivot_longer3_cell_values.png){fig-align=\"center\"}\n\n## `pivot_longer()`\n\nThis function usually takes three arguments:\n\n1. `cols`: The columns that need to be pivoted (are not variables)\n2. `names_to`: Names the new variable that is stored in multiple columns\n3. `values_to`: Names the variable stored in the cell values\n\n![](images/pivot_longer1_variables.png){fig-align=\"center\"}\n\n## `pivot_longer()` Example\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nbillboard_2000 <- billboard_2000_raw |> \n  pivot_longer(cols = starts_with(\"wk\"), # <1>\n               names_to =\"week\",\n               values_to = \"rank\")\n\nbillboard_2000 |> head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 7\n    year artist track                   time   date.entered week   rank\n   <int> <chr>  <chr>                   <time> <date>       <chr> <int>\n 1  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk1      87\n 2  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk2      82\n 3  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk3      72\n 4  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk4      77\n 5  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk5      87\n 6  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk6      94\n 7  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk7      99\n 8  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk8      NA\n 9  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk9      NA\n10  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26   wk10     NA\n```\n\n\n:::\n:::\n\n\n\n1. `starts_with()` is one of the helper functions from [`tidyselect`](https://tidyselect.r-lib.org/index.html) that helps select certain common patterns. We could have also used `cols = wk1:wk76`. \n\n. . . \n\nNow we have a single week column!\n\n## Lots of Missing Values?!\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nglimpse(billboard_2000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 24,092\nColumns: 7\n$ year         <int> 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 200…\n$ artist       <chr> \"2 Pac\", \"2 Pac\", \"2 Pac\", \"2 Pac\", \"2 Pac\", \"2 Pac\", \"2 …\n$ track        <chr> \"Baby Don't Cry (Keep...\", \"Baby Don't Cry (Keep...\", \"Ba…\n$ time         <time> 04:22:00, 04:22:00, 04:22:00, 04:22:00, 04:22:00, 04:22:…\n$ date.entered <date> 2000-02-26, 2000-02-26, 2000-02-26, 2000-02-26, 2000-02-…\n$ week         <chr> \"wk1\", \"wk2\", \"wk3\", \"wk4\", \"wk5\", \"wk6\", \"wk7\", \"wk8\", \"…\n$ rank         <int> 87, 82, 72, 77, 87, 94, 99, NA, NA, NA, NA, NA, NA, NA, N…\n```\n\n\n:::\n:::\n\n\n\n::: {.fragment}\nIt looks like 2 Pac's song \"Baby Don't Cry\" was only on the Billboard Hot 100 for 7 weeks and then dropped off the charts. \n:::\n. . . \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nsummary(billboard_2000$rank)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1.00   26.00   51.00   51.05   76.00  100.00   18785 \n```\n\n\n:::\n:::\n\n\n\n::: {.fragment}\nWe don't want to keep the 18785 rows with missing ranks.\n:::\n\n## Pivoting Better: `values_drop_na`\n\nAdding the argument `values_drop_na = TRUE` to `pivot_longer()` will remove rows with missing ranks. Since these `NA`s don’t really represent unknown observations (i.e. they were forced to exist by the structure of the dataset) this is an appropriate approach here. \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code  code-line-numbers=\"|5\"}\nbillboard_2000 <- billboard_2000_raw %>%\n  pivot_longer(cols = wk1:wk76, \n               names_to = \"week\", \n               values_to = \"rank\", \n               values_drop_na = TRUE)\nsummary(billboard_2000$rank)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00   26.00   51.00   51.05   76.00  100.00 \n```\n\n\n:::\n:::\n\n\n\n. . . \n\nNo more `NA` values!\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\ndim(billboard_2000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5307    7\n```\n\n\n:::\n:::\n\n\n\n. . . \n\nAnd way fewer rows!\n\n## `parse_number()`\n\nThe week column is of the type `character`, but it should be `numeric.`\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nhead(billboard_2000$week)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"wk1\" \"wk2\" \"wk3\" \"wk4\" \"wk5\" \"wk6\"\n```\n\n\n:::\n:::\n\n\n\n. . . \n\n`parse_number()` grabs just the numeric information from a character string:\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nbillboard_2000 <- billboard_2000 |> \n    mutate(week = parse_number(week)) # <2>\nsummary(billboard_2000$week)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    5.00   10.00   11.47   16.00   65.00 \n```\n\n\n:::\n:::\n\n\n2. You can use `mutate()` to overwrite existing columns. \n\n## Use `pivot_longer` arguments\n\nAlternatively (and more efficiently), there are a number of optional arguments for `pivot_longer` that are meant to help deal with naming issues.\n\n. . . \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nbillboard_2000 <- billboard_2000_raw %>%\n  pivot_longer(starts_with(\"wk\"), \n               names_to        = \"week\", \n               values_to       = \"rank\",\n               values_drop_na  = TRUE,\n               names_prefix    = \"wk\", # <3>\n               names_transform = list(week = as.integer)) # <4>\n\nhead(billboard_2000, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 7\n   year artist track                   time   date.entered  week  rank\n  <int> <chr>  <chr>                   <time> <date>       <int> <int>\n1  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26       1    87\n2  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26       2    82\n3  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26       3    72\n4  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26       4    77\n5  2000 2 Pac  Baby Don't Cry (Keep... 04:22  2000-02-26       5    87\n```\n\n\n:::\n:::\n\n\n\n3. `names_prefix` is used to remove \"wk\" from the values of `week`\n4. `names_transform` converts `week` into an integer number.\n\n## Multiple Variables in Column Names\n\nA more challenging situation occurs when you have multiple pieces of information crammed into the column names, and you would like to store these in separate new variables.\n\n. . . \n\nThis dataset contains tuberculosis diagnoses collected by the World Health Organization. \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nwho2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7,240 × 58\n   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554 sp_m_5564\n   <chr>       <dbl>    <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n 1 Afghanistan  1980       NA        NA        NA        NA        NA        NA\n 2 Afghanistan  1981       NA        NA        NA        NA        NA        NA\n 3 Afghanistan  1982       NA        NA        NA        NA        NA        NA\n 4 Afghanistan  1983       NA        NA        NA        NA        NA        NA\n 5 Afghanistan  1984       NA        NA        NA        NA        NA        NA\n 6 Afghanistan  1985       NA        NA        NA        NA        NA        NA\n 7 Afghanistan  1986       NA        NA        NA        NA        NA        NA\n 8 Afghanistan  1987       NA        NA        NA        NA        NA        NA\n 9 Afghanistan  1988       NA        NA        NA        NA        NA        NA\n10 Afghanistan  1989       NA        NA        NA        NA        NA        NA\n# ℹ 7,230 more rows\n# ℹ 50 more variables: sp_m_65 <dbl>, sp_f_014 <dbl>, sp_f_1524 <dbl>,\n#   sp_f_2534 <dbl>, sp_f_3544 <dbl>, sp_f_4554 <dbl>, sp_f_5564 <dbl>,\n#   sp_f_65 <dbl>, sn_m_014 <dbl>, sn_m_1524 <dbl>, sn_m_2534 <dbl>,\n#   sn_m_3544 <dbl>, sn_m_4554 <dbl>, sn_m_5564 <dbl>, sn_m_65 <dbl>,\n#   sn_f_014 <dbl>, sn_f_1524 <dbl>, sn_f_2534 <dbl>, sn_f_3544 <dbl>,\n#   sn_f_4554 <dbl>, sn_f_5564 <dbl>, sn_f_65 <dbl>, ep_m_014 <dbl>, …\n```\n\n\n:::\n:::\n\n\n\n. . . \n\nThe first two columns are self explanatory but what's going on with the rest?\n\n## Multiple Variables in Column Names\n\nData documentation and some minor investigation would lead you to figure out that the three elements in each of these column names are actually data!\n\n* The first piece, `sp`/`sn`/`rel`/`ep`, describes the method used for the diagnosis\n* The second piece, `m`/`f` is the gender (coded as a binary variable in this dataset)\n* The third piece, `014`/`1524`/`2534`/`3544`/`4554`/`5564`/`65` is the age range (014 represents 0-14, for example)\n\n. . . \n\nTo organize the six pieces of information in this dataset into six separate columns, we use `pivot_longer()` with a vector of column names for `names_to` and instructors for splitting the original variable names into pieces for `names_sep` as well as a column name for `values_to`!\n\n## Multiple Variables in Column Names\n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nwho2 |> \n  pivot_longer(\n    cols = !(country:year),\n    names_to = c(\"diagnosis\", \"gender\", \"age\"), \n    names_sep = \"_\", # <5>\n    values_to = \"count\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 405,440 × 6\n   country      year diagnosis gender age   count\n   <chr>       <dbl> <chr>     <chr>  <chr> <dbl>\n 1 Afghanistan  1980 sp        m      014      NA\n 2 Afghanistan  1980 sp        m      1524     NA\n 3 Afghanistan  1980 sp        m      2534     NA\n 4 Afghanistan  1980 sp        m      3544     NA\n 5 Afghanistan  1980 sp        m      4554     NA\n 6 Afghanistan  1980 sp        m      5564     NA\n 7 Afghanistan  1980 sp        m      65       NA\n 8 Afghanistan  1980 sp        f      014      NA\n 9 Afghanistan  1980 sp        f      1524     NA\n10 Afghanistan  1980 sp        f      2534     NA\n# ℹ 405,430 more rows\n```\n\n\n:::\n:::\n\n\n\n5. You can use `names_pattern` instead of `names_sep` to extract variables from more complicated naming scenarios if you are familiar with regular expressions. \n\n## Variable & Values in Column Names\n\nThis dataset contains data about five families, with the names and dates of birth of up to two children. \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nhousehold\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 5\n  family dob_child1 dob_child2 name_child1 name_child2\n   <int> <date>     <date>     <chr>       <chr>      \n1      1 1998-11-26 2000-01-29 Susan       Jose       \n2      2 1996-06-22 NA         Mark        <NA>       \n3      3 2002-07-11 2004-04-05 Sam         Seth       \n4      4 2004-10-10 2009-08-27 Craig       Khai       \n5      5 2000-12-05 2005-02-28 Parker      Gracie     \n```\n\n\n:::\n:::\n\n\n\n. . . \n\nThe new challenge in this dataset is that the column names contain the names of two variables (`dob`, `name`) and the values of another (`child`, with values `1` or `2`).\n\n## Variable & Values in Column Names\n\n\n\n::: {.cell output-location='column-fragment'}\n\n```{.r .cell-code}\nhousehold |> \n  pivot_longer(\n    cols = !family, \n    names_to = c(\".value\", \"child\"), # <6>\n    names_sep = \"_\", \n    values_drop_na = TRUE # <7> \n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 × 4\n  family child  dob        name  \n   <int> <chr>  <date>     <chr> \n1      1 child1 1998-11-26 Susan \n2      1 child2 2000-01-29 Jose  \n3      2 child1 1996-06-22 Mark  \n4      3 child1 2002-07-11 Sam   \n5      3 child2 2004-04-05 Seth  \n6      4 child1 2004-10-10 Craig \n7      4 child2 2009-08-27 Khai  \n8      5 child1 2000-12-05 Parker\n9      5 child2 2005-02-28 Gracie\n```\n\n\n:::\n:::\n\n\n\n6. `.value` isn’t the name of a variable but a unique value that tells `pivot_longer` to use the first component of the pivoted column name as a variable name in the output. \n7. Using `values_drop_na = TRUE` again since not every family has 2 children.\n\n. . . \n\n![](images/pivot_longer5_names-and-values.png){width=75% fig-align=\"center\"}\n\n## `pivot_wider`\n\n`pivot_wider()` is the opposite of `pivot_longer()`, which you use if you have data for the same observation taking up multiple rows.\n\n. . . \n\nHere's an example of data that we probably want to pivot wider (unless we want to plot each statistic in its own facet):\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  Group Statistic Value\n  <chr> <chr>     <dbl>\n1 A     Mean       1.28\n2 A     Median     1   \n3 A     SD         0.72\n4 B     Mean       2.81\n5 B     Median     2   \n6 B     SD         1.33\n```\n\n\n:::\n:::\n\n\n\n. . . \n\nA common cue to use `pivot_wider()` is having measurements of different quantities in the same column.\n\n## `pivot_wider` Example \n\n\n\n::: {.cell output-location='fragment'}\n\n```{.r .cell-code}\nwide_stats <- long_stats |> \n  pivot_wider(id_cols = Group, # <8>\n              names_from = Statistic, # <9>\n              values_from = Value) # <10>\nwide_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  Group  Mean Median    SD\n  <chr> <dbl>  <dbl> <dbl>\n1 A      1.28      1  0.72\n2 B      2.81      2  1.33\n```\n\n\n:::\n:::\n\n\n\n8. `id_cols` is the column that uniquely identifies each row in the new dataset. Default is everything not in `names_from` and `values_from`.\n9. `names_from` provides the names that will be used for the new columns\n10. `values_from` provides the values that will be used to populate the cells of the new columns.\n\n. . . \n\n[`pivot_wider()`](https://tidyr.tidyverse.org/reference/pivot_wider.html) also has a number of optional `names_*` and `values_*` arguments for more complicated transformations. \n\n. . . \n\n::: {.callout-warning icon=false}\n## <span style=\"color:orange\">{{< fa triangle-exclamation >}}</span> Nested Data\nIf there are multiple rows in the input that correspond to one cell in the output you'll get a list-column. This means that you 1) need to fix something in your code/data because it shouldn't be nested in this way or 2) need to use `unnest_wider()` or `unnest_longer()` in order to access this column of data. More on this [here](https://r4ds.hadley.nz/rectangling.html#unnesting). \n:::\n\n## Useful Resources\n\n. . . \n\n**Cheatsheets:**\n\n* [readr](https://rstudio.github.io/cheatsheets/data-import.pdf)\n* [dplyr](https://rstudio.github.io/cheatsheets/data-transformation.pdf)\n* [tidyr](https://rstudio.github.io/cheatsheets/tidyr.pdf)\n\n\n**Introductory Book:**\n\n[R for Data Science (2e)](https://r4ds.hadley.nz/) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\n\n# {data-menu-title=\"R Knowledge Comic\" .section-title background-image=\"images/r_knowledge.png\"}\n\n## CSSCR Consulting Services\n\nCSSCR is a resource center for the social science departments^[Constituent member departments include The College of Education, The Department of Anthropology, The Department of Communication, The Department of Economics, The Department of Geography, The Department of Political Science, The Department of Psychology, The Department of Sociology, The Jackson School of International Studies, and The School of Social Work] at the University of Washington.\n\n. . . \n\nAs you continue to learn `R` feel free to drop by with any/all of your `R` coding questions. Below are our hours for the quarter: \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"qmivjvugfr\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#qmivjvugfr table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#qmivjvugfr thead, #qmivjvugfr tbody, #qmivjvugfr tfoot, #qmivjvugfr tr, #qmivjvugfr td, #qmivjvugfr th {\n  border-style: none;\n}\n\n#qmivjvugfr p {\n  margin: 0;\n  padding: 0;\n}\n\n#qmivjvugfr .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#qmivjvugfr .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#qmivjvugfr .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#qmivjvugfr .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#qmivjvugfr .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#qmivjvugfr .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#qmivjvugfr .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#qmivjvugfr .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#qmivjvugfr .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#qmivjvugfr .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#qmivjvugfr .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#qmivjvugfr .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#qmivjvugfr .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#qmivjvugfr .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#qmivjvugfr .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qmivjvugfr .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#qmivjvugfr .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#qmivjvugfr .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#qmivjvugfr .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qmivjvugfr .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#qmivjvugfr .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qmivjvugfr .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#qmivjvugfr .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qmivjvugfr .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#qmivjvugfr .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#qmivjvugfr .gt_left {\n  text-align: left;\n}\n\n#qmivjvugfr .gt_center {\n  text-align: center;\n}\n\n#qmivjvugfr .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#qmivjvugfr .gt_font_normal {\n  font-weight: normal;\n}\n\n#qmivjvugfr .gt_font_bold {\n  font-weight: bold;\n}\n\n#qmivjvugfr .gt_font_italic {\n  font-style: italic;\n}\n\n#qmivjvugfr .gt_super {\n  font-size: 65%;\n}\n\n#qmivjvugfr .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#qmivjvugfr .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#qmivjvugfr .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#qmivjvugfr .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#qmivjvugfr .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#qmivjvugfr .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#qmivjvugfr .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#qmivjvugfr .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#qmivjvugfr div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_heading\">\n      <td colspan=\"3\" class=\"gt_heading gt_title gt_font_normal\" style>The Center for Social Science Computation and Research</td>\n    </tr>\n    <tr class=\"gt_heading\">\n      <td colspan=\"3\" class=\"gt_heading gt_subtitle gt_font_normal gt_bottom_border\" style>Consulting Hours for Fall 2024</td>\n    </tr>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"a::stub\"></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"drop_in\">In-Person<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"evening\">Virtual<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>2</sup></span></th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><th id=\"stub_1_1\" scope=\"row\" class=\"gt_row gt_left gt_stub\">Monday</th>\n<td headers=\"stub_1_1 drop_in\" class=\"gt_row gt_left\" style=\"background-color: #EEE8AA; color: #000000;\">8am - 6pm</td>\n<td headers=\"stub_1_1 evening\" class=\"gt_row gt_left\" style=\"background-color: #BCBDDC; color: #000000;\">6 - 9pm</td></tr>\n    <tr><th id=\"stub_1_2\" scope=\"row\" class=\"gt_row gt_left gt_stub\">Tuesday</th>\n<td headers=\"stub_1_2 drop_in\" class=\"gt_row gt_left\" style=\"background-color: #EEE8AA; color: #000000;\">8am - 6pm</td>\n<td headers=\"stub_1_2 evening\" class=\"gt_row gt_left\" style=\"background-color: #BCBDDC; color: #000000;\">6 - 9pm</td></tr>\n    <tr><th id=\"stub_1_3\" scope=\"row\" class=\"gt_row gt_left gt_stub\">Wednesday</th>\n<td headers=\"stub_1_3 drop_in\" class=\"gt_row gt_left\" style=\"background-color: #EEE8AA; color: #000000;\">8am - 6pm</td>\n<td headers=\"stub_1_3 evening\" class=\"gt_row gt_left\" style=\"background-color: #BCBDDC; color: #000000;\">6 - 9pm</td></tr>\n    <tr><th id=\"stub_1_4\" scope=\"row\" class=\"gt_row gt_left gt_stub\">Thursday</th>\n<td headers=\"stub_1_4 drop_in\" class=\"gt_row gt_left\" style=\"background-color: #EEE8AA; color: #000000;\">8am - 6pm</td>\n<td headers=\"stub_1_4 evening\" class=\"gt_row gt_left\" style=\"background-color: #BCBDDC; color: #000000;\">6 - 9pm</td></tr>\n    <tr><th id=\"stub_1_5\" scope=\"row\" class=\"gt_row gt_left gt_stub\">Friday</th>\n<td headers=\"stub_1_5 drop_in\" class=\"gt_row gt_left\" style=\"background-color: #FAFAD2; color: #000000;\">8am - 5pm</td>\n<td headers=\"stub_1_5 evening\" class=\"gt_row gt_left\" style=\"background-color: #EFEDF5; color: #000000;\"></td></tr>\n  </tbody>\n  \n  <tfoot>\n    <tr class=\"gt_footnotes\">\n      <td class=\"gt_footnote\" colspan=\"3\">\n        <div style=\"padding-bottom:2px;\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span> Drop-in @ Savery 119 <span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>2</sup></span> Online Via Zoom</div>\n      </td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n# Thanks!{.section-title background-color=\"#4B2E83\"}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}